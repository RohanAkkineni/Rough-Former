{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RohanAkkineni/Rough-Former/blob/main/Rough_Former.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Aprofy_CIl6r"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nn4TkpTkJIis",
        "outputId": "830636e7-29cc-4b59-dddf-d881d0cd8ff4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'RFormer' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/AlvaroArroyo/RFormer.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tkuFfuGIJOVc",
        "outputId": "42335b71-236d-458d-fa92-ce9dd3d94120"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "condacolab_install.log\tREADME.md  rformer.yml\tsrc\n"
          ]
        }
      ],
      "source": [
        "os.chdir(\"RFormer\")\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3YZIXfjmJzRo",
        "outputId": "8fb3f462-f433-4d96-97d9-0da22d5347f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting iisignature\n",
            "  Using cached iisignature-0.24-cp311-cp311-linux_x86_64.whl\n",
            "Collecting ray\n",
            "  Using cached ray-2.46.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (19 kB)\n",
            "Collecting sktime\n",
            "  Using cached sktime-0.37.0-py3-none-any.whl.metadata (34 kB)\n",
            "Collecting librosa\n",
            "  Downloading librosa-0.11.0-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/site-packages (4.67.1)\n",
            "Collecting tensorboard\n",
            "  Downloading tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting aeon\n",
            "  Using cached aeon-1.1.0-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting torchvision\n",
            "  Downloading torchvision-0.22.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
            "Collecting torchaudio\n",
            "  Downloading torchaudio-2.7.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.19.11-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Collecting torch\n",
            "  Downloading torch-2.7.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (29 kB)\n",
            "Requirement already satisfied: numpy>1.7 in /usr/local/lib/python3.11/site-packages (from iisignature) (2.2.5)\n",
            "Collecting click>=7.0 (from ray)\n",
            "  Downloading click-8.2.0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting filelock (from ray)\n",
            "  Downloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting jsonschema (from ray)\n",
            "  Downloading jsonschema-4.23.0-py3-none-any.whl.metadata (7.9 kB)\n",
            "Collecting msgpack<2.0.0,>=1.0.0 (from ray)\n",
            "  Downloading msgpack-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/site-packages (from ray) (24.2)\n",
            "Collecting protobuf!=3.19.5,>=3.15.3 (from ray)\n",
            "  Downloading protobuf-6.30.2-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
            "Collecting pyyaml (from ray)\n",
            "  Downloading PyYAML-6.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/site-packages (from ray) (2.32.3)\n",
            "Collecting pandas (from ray[tune])\n",
            "  Downloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
            "Collecting tensorboardX>=1.9 (from ray[tune])\n",
            "  Using cached tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting pyarrow>=9.0.0 (from ray[tune])\n",
            "  Downloading pyarrow-20.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting fsspec (from ray[tune])\n",
            "  Downloading fsspec-2025.3.2-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting joblib<1.5,>=1.2.0 (from sktime)\n",
            "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting scikit-base<0.13.0,>=0.6.1 (from sktime)\n",
            "  Using cached scikit_base-0.12.2-py3-none-any.whl.metadata (8.8 kB)\n",
            "Collecting scikit-learn<1.7.0,>=0.24 (from sktime)\n",
            "  Downloading scikit_learn-1.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.2 in /usr/local/lib/python3.11/site-packages (from sktime) (1.15.2)\n",
            "Collecting audioread>=2.1.9 (from librosa)\n",
            "  Downloading audioread-3.0.1-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting numba>=0.51.0 (from librosa)\n",
            "  Downloading numba-0.61.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.8 kB)\n",
            "Collecting decorator>=4.3.0 (from librosa)\n",
            "  Downloading decorator-5.2.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting soundfile>=0.12.1 (from librosa)\n",
            "  Downloading soundfile-0.13.1-py2.py3-none-manylinux_2_28_x86_64.whl.metadata (16 kB)\n",
            "Collecting pooch>=1.1 (from librosa)\n",
            "  Downloading pooch-1.8.2-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting soxr>=0.3.2 (from librosa)\n",
            "  Downloading soxr-0.5.0.post1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Collecting typing_extensions>=4.1.1 (from librosa)\n",
            "  Downloading typing_extensions-4.13.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting lazy_loader>=0.1 (from librosa)\n",
            "  Downloading lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting absl-py>=0.4 (from tensorboard)\n",
            "  Downloading absl_py-2.2.2-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting grpcio>=1.48.2 (from tensorboard)\n",
            "  Downloading grpcio-1.71.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Collecting markdown>=2.6.8 (from tensorboard)\n",
            "  Downloading markdown-3.8-py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/site-packages (from tensorboard) (65.6.3)\n",
            "Collecting six>1.9 (from tensorboard)\n",
            "  Downloading six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard)\n",
            "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting werkzeug>=1.0.1 (from tensorboard)\n",
            "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting deprecated>=1.2.13 (from aeon)\n",
            "  Downloading Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting pillow!=8.3.*,>=5.3.0 (from torchvision)\n",
            "  Downloading pillow-11.2.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (8.9 kB)\n",
            "Collecting sympy>=1.13.3 (from torch)\n",
            "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting networkx (from torch)\n",
            "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting jinja2 (from torch)\n",
            "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.6.77 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.6.77 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.6.80 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.5.1.17 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.6.4.1 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.3.0.4 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.7.77 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.7.1.2 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.5.4.2 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparselt-cu12==0.6.3 (from torch)\n",
            "  Downloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting nvidia-nccl-cu12==2.26.2 (from torch)\n",
            "  Downloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.6.77 (from torch)\n",
            "  Downloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.6.85 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufile-cu12==1.11.1.6 (from torch)\n",
            "  Downloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting triton==3.3.0 (from torch)\n",
            "  Downloading triton-3.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting docker-pycreds>=0.4.0 (from wandb)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb)\n",
            "  Downloading GitPython-3.1.44-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/site-packages (from wandb) (4.3.6)\n",
            "Collecting psutil>=5.0.0 (from wandb)\n",
            "  Downloading psutil-7.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
            "Collecting pydantic<3 (from wandb)\n",
            "  Downloading pydantic-2.11.4-py3-none-any.whl.metadata (66 kB)\n",
            "Collecting sentry-sdk>=2.0.0 (from wandb)\n",
            "  Downloading sentry_sdk-2.28.0-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Collecting setproctitle (from wandb)\n",
            "  Downloading setproctitle-1.3.6-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Collecting wrapt<2,>=1.10 (from deprecated>=1.2.13->aeon)\n",
            "  Downloading wrapt-1.17.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting llvmlite<0.45,>=0.44.0dev0 (from numba>=0.51.0->librosa)\n",
            "  Downloading llvmlite-0.44.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
            "Collecting python-dateutil>=2.8.2 (from pandas->ray[tune])\n",
            "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting pytz>=2020.1 (from pandas->ray[tune])\n",
            "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tzdata>=2022.7 (from pandas->ray[tune])\n",
            "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting annotated-types>=0.6.0 (from pydantic<3->wandb)\n",
            "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting pydantic-core==2.33.2 (from pydantic<3->wandb)\n",
            "  Downloading pydantic_core-2.33.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting typing-inspection>=0.4.0 (from pydantic<3->wandb)\n",
            "  Downloading typing_inspection-0.4.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/site-packages (from requests->ray) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/site-packages (from requests->ray) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/site-packages (from requests->ray) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/site-packages (from requests->ray) (2025.4.26)\n",
            "Collecting threadpoolctl>=3.1.0 (from scikit-learn<1.7.0,>=0.24->sktime)\n",
            "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/site-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)\n",
            "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting MarkupSafe>=2.1.1 (from werkzeug>=1.0.1->tensorboard)\n",
            "  Downloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
            "Collecting attrs>=22.2.0 (from jsonschema->ray)\n",
            "  Downloading attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema->ray)\n",
            "  Downloading jsonschema_specifications-2025.4.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting referencing>=0.28.4 (from jsonschema->ray)\n",
            "  Downloading referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting rpds-py>=0.7.1 (from jsonschema->ray)\n",
            "  Downloading rpds_py-0.24.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
            "Using cached ray-2.46.0-cp311-cp311-manylinux2014_x86_64.whl (68.5 MB)\n",
            "Using cached sktime-0.37.0-py3-none-any.whl (37.0 MB)\n",
            "Downloading librosa-0.11.0-py3-none-any.whl (260 kB)\n",
            "Downloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m90.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached aeon-1.1.0-py3-none-any.whl (8.3 MB)\n",
            "Downloading torchvision-0.22.0-cp311-cp311-manylinux_2_28_x86_64.whl (7.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m154.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.7.0-cp311-cp311-manylinux_2_28_x86_64.whl (865.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m865.2/865.2 MB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m393.1/393.1 MB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m157.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m183.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m897.7/897.7 kB\u001b[0m \u001b[31m53.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (571.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m571.0/571.0 MB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m200.2/200.2 MB\u001b[0m \u001b[31m68.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m65.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m88.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m158.2/158.2 MB\u001b[0m \u001b[31m68.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m216.6/216.6 MB\u001b[0m \u001b[31m73.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl (156.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m156.8/156.8 MB\u001b[0m \u001b[31m68.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m201.3/201.3 MB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m158.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
            "Downloading triton-3.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (156.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m156.5/156.5 MB\u001b[0m \u001b[31m68.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchaudio-2.7.0-cp311-cp311-manylinux_2_28_x86_64.whl (3.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m112.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wandb-0.19.11-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.4/21.4 MB\u001b[0m \u001b[31m193.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading absl_py-2.2.2-py3-none-any.whl (135 kB)\n",
            "Downloading audioread-3.0.1-py3-none-any.whl (23 kB)\n",
            "Downloading click-8.2.0-py3-none-any.whl (102 kB)\n",
            "Downloading decorator-5.2.1-py3-none-any.whl (9.2 kB)\n",
            "Downloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
            "Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Downloading GitPython-3.1.44-py3-none-any.whl (207 kB)\n",
            "Downloading grpcio-1.71.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m150.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
            "Downloading lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
            "Downloading markdown-3.8-py3-none-any.whl (106 kB)\n",
            "Downloading msgpack-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (403 kB)\n",
            "Downloading numba-0.61.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m142.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m173.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow-11.2.1-cp311-cp311-manylinux_2_28_x86_64.whl (4.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m141.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pooch-1.8.2-py3-none-any.whl (64 kB)\n",
            "Downloading protobuf-6.30.2-cp39-abi3-manylinux2014_x86_64.whl (316 kB)\n",
            "Downloading psutil-7.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (277 kB)\n",
            "Downloading pyarrow-20.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (42.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m42.3/42.3 MB\u001b[0m \u001b[31m59.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic-2.11.4-py3-none-any.whl (443 kB)\n",
            "Downloading pydantic_core-2.33.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m98.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached scikit_base-0.12.2-py3-none-any.whl (142 kB)\n",
            "Downloading scikit_learn-1.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m170.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sentry_sdk-2.28.0-py2.py3-none-any.whl (341 kB)\n",
            "Downloading six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
            "Downloading soundfile-0.13.1-py2.py3-none-manylinux_2_28_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m75.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading soxr-0.5.0.post1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (252 kB)\n",
            "Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m139.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m169.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "Downloading typing_extensions-4.13.2-py3-none-any.whl (45 kB)\n",
            "Downloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
            "Downloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
            "Downloading fsspec-2025.3.2-py3-none-any.whl (194 kB)\n",
            "Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "Downloading jsonschema-4.23.0-py3-none-any.whl (88 kB)\n",
            "Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m91.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PyYAML-6.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (762 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m763.0/763.0 kB\u001b[0m \u001b[31m44.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading setproctitle-1.3.6-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31 kB)\n",
            "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
            "Downloading attrs-25.3.0-py3-none-any.whl (63 kB)\n",
            "Downloading gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
            "Downloading jsonschema_specifications-2025.4.1-py3-none-any.whl (18 kB)\n",
            "Downloading llvmlite-0.44.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m42.4/42.4 MB\u001b[0m \u001b[31m65.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\n",
            "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
            "Downloading referencing-0.36.2-py3-none-any.whl (26 kB)\n",
            "Downloading rpds_py-0.24.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (389 kB)\n",
            "Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
            "Downloading typing_inspection-0.4.0-py3-none-any.whl (14 kB)\n",
            "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
            "Downloading wrapt-1.17.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (83 kB)\n",
            "Downloading smmap-5.0.2-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: pytz, nvidia-cusparselt-cu12, mpmath, wrapt, tzdata, typing_extensions, triton, threadpoolctl, tensorboard-data-server, sympy, soxr, smmap, six, setproctitle, sentry-sdk, scikit-base, rpds-py, pyyaml, pyarrow, psutil, protobuf, pillow, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, msgpack, MarkupSafe, markdown, llvmlite, lazy_loader, joblib, iisignature, grpcio, fsspec, filelock, decorator, click, audioread, attrs, annotated-types, absl-py, werkzeug, typing-inspection, tensorboardX, soundfile, scikit-learn, referencing, python-dateutil, pydantic-core, pooch, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, numba, jinja2, gitdb, docker-pycreds, deprecated, tensorboard, pydantic, pandas, nvidia-cusolver-cu12, librosa, jsonschema-specifications, gitpython, wandb, torch, sktime, jsonschema, aeon, torchvision, torchaudio, ray\n",
            "Successfully installed MarkupSafe-3.0.2 absl-py-2.2.2 aeon-1.1.0 annotated-types-0.7.0 attrs-25.3.0 audioread-3.0.1 click-8.2.0 decorator-5.2.1 deprecated-1.2.18 docker-pycreds-0.4.0 filelock-3.18.0 fsspec-2025.3.2 gitdb-4.0.12 gitpython-3.1.44 grpcio-1.71.0 iisignature-0.24 jinja2-3.1.6 joblib-1.4.2 jsonschema-4.23.0 jsonschema-specifications-2025.4.1 lazy_loader-0.4 librosa-0.11.0 llvmlite-0.44.0 markdown-3.8 mpmath-1.3.0 msgpack-1.1.0 networkx-3.4.2 numba-0.61.2 nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvrtc-cu12-12.6.77 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-9.5.1.17 nvidia-cufft-cu12-11.3.0.4 nvidia-cufile-cu12-1.11.1.6 nvidia-curand-cu12-10.3.7.77 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-cusparselt-cu12-0.6.3 nvidia-nccl-cu12-2.26.2 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvtx-cu12-12.6.77 pandas-2.2.3 pillow-11.2.1 pooch-1.8.2 protobuf-6.30.2 psutil-7.0.0 pyarrow-20.0.0 pydantic-2.11.4 pydantic-core-2.33.2 python-dateutil-2.9.0.post0 pytz-2025.2 pyyaml-6.0.2 ray-2.46.0 referencing-0.36.2 rpds-py-0.24.0 scikit-base-0.12.2 scikit-learn-1.6.1 sentry-sdk-2.28.0 setproctitle-1.3.6 six-1.17.0 sktime-0.37.0 smmap-5.0.2 soundfile-0.13.1 soxr-0.5.0.post1 sympy-1.14.0 tensorboard-2.19.0 tensorboard-data-server-0.7.2 tensorboardX-2.6.2.2 threadpoolctl-3.6.0 torch-2.7.0 torchaudio-2.7.0 torchvision-0.22.0 triton-3.3.0 typing-inspection-0.4.0 typing_extensions-4.13.2 tzdata-2025.2 wandb-0.19.11 werkzeug-3.1.3 wrapt-1.17.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "dateutil",
                  "pytz",
                  "six"
                ]
              },
              "id": "aaff231c152c4fbe9f979514fa07fd66"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install iisignature ray \"ray[tune]\" sktime librosa tqdm tensorboard aeon torchvision torchaudio wandb torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-C2-3qqKU8j",
        "outputId": "c0f25282-4d3a-4b34-b6cc-62905f26ea67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ¨ðŸ°âœ¨ Everything looks OK!\n"
          ]
        }
      ],
      "source": [
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5okq-hHKdK5",
        "outputId": "70627564-3507-45c0-d4f4-1bd712b048b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ¨ðŸ°âœ¨ Everything looks OK!\n"
          ]
        }
      ],
      "source": [
        "import condacolab\n",
        "condacolab.check()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZuaGkwINKf3G",
        "outputId": "dee37e23-0be3-40bd-8d46-6366e9194944"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preparing transaction: ...working... done\n",
            "Verifying transaction: ...working... done\n",
            "Executing transaction: ...working... By downloading and using the CUDA Toolkit conda packages, you accept the terms and conditions of the CUDA End User License Agreement (EULA): https://docs.nvidia.com/cuda/eula/index.html\n",
            "\n",
            "done\n"
          ]
        }
      ],
      "source": [
        "!mamba install -q openmm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2tQF_MaKq5m",
        "outputId": "de71636b-92c4-4e87-a737-f52b81499edf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "EnvironmentFileNotFound: '/content/rformer.yml' file not found\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!conda env create -f rformer.yml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "stvpFFxEMCcz",
        "outputId": "30eb0fbf-eaaf-4ea5-9182-5d8c6a1d2b50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "no change     /usr/local/condabin/conda\n",
            "no change     /usr/local/bin/conda\n",
            "no change     /usr/local/bin/conda-env\n",
            "no change     /usr/local/bin/activate\n",
            "no change     /usr/local/bin/deactivate\n",
            "no change     /usr/local/etc/profile.d/conda.sh\n",
            "no change     /usr/local/etc/fish/conf.d/conda.fish\n",
            "no change     /usr/local/shell/condabin/Conda.psm1\n",
            "no change     /usr/local/shell/condabin/conda-hook.ps1\n",
            "no change     /usr/local/lib/python3.11/site-packages/xontrib/conda.xsh\n",
            "no change     /usr/local/etc/profile.d/conda.csh\n",
            "modified      /root/.bashrc\n",
            "\n",
            "==> For changes to take effect, close and re-open your current shell. <==\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!conda init"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_C5fBF6VMn8m",
        "outputId": "72c3b8f4-1332-4dff-e386-f5201e8e0139"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Channels:\n",
            " - conda-forge\n",
            "Platform: linux-64\n",
            "Collecting package metadata (repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "Solving environment: - \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - numpy\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    conda-24.11.3              |  py311h38be061_0         1.1 MB  conda-forge\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:         1.1 MB\n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "  conda                             24.11.2-py311h38be061_1 --> 24.11.3-py311h38be061_0 \n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages:\n",
            "                                                                        \n",
            "Preparing transaction: - \b\bdone\n",
            "Verifying transaction: | \b\bdone\n",
            "Executing transaction: - \b\bdone\n"
          ]
        }
      ],
      "source": [
        "# For example, install a package:\n",
        "!conda install -y numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wK-w0LtK1nd",
        "outputId": "e1ee790a-a515-4cdb-d3eb-a648b166ad10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "no change     /usr/local/condabin/conda\n",
            "no change     /usr/local/bin/conda\n",
            "no change     /usr/local/bin/conda-env\n",
            "no change     /usr/local/bin/activate\n",
            "no change     /usr/local/bin/deactivate\n",
            "no change     /usr/local/etc/profile.d/conda.sh\n",
            "no change     /usr/local/etc/fish/conf.d/conda.fish\n",
            "no change     /usr/local/shell/condabin/Conda.psm1\n",
            "no change     /usr/local/shell/condabin/conda-hook.ps1\n",
            "no change     /usr/local/lib/python3.11/site-packages/xontrib/conda.xsh\n",
            "no change     /usr/local/etc/profile.d/conda.csh\n",
            "no change     /root/.bashrc\n",
            "No action taken.\n",
            "\n",
            "CondaError: Run 'conda init' before 'conda activate'\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!conda init\n",
        "!conda activate rformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9YVElcJDM3Gj",
        "outputId": "bfb3b7dd-50bc-4172-d282-add2cfb6fc26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Channels:\n",
            " - conda-forge\n",
            "Platform: linux-64\n",
            "Collecting package metadata (repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Solving environment: | \b\b/ \b\bdone\n",
            "\n",
            "\n",
            "==> WARNING: A newer version of conda exists. <==\n",
            "    current version: 24.11.3\n",
            "    latest version: 25.3.1\n",
            "\n",
            "Please update conda by running\n",
            "\n",
            "    $ conda update -n base -c conda-forge conda\n",
            "\n",
            "\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local/envs/rformer\n",
            "\n",
            "  added / updated specs:\n",
            "    - python=3.9\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    ld_impl_linux-64-2.43      |       h712a8e2_4         656 KB  conda-forge\n",
            "    libexpat-2.7.0             |       h5888daf_0          73 KB  conda-forge\n",
            "    libffi-3.4.6               |       h2dba641_1          56 KB  conda-forge\n",
            "    libgcc-15.1.0              |       h767d61c_2         810 KB  conda-forge\n",
            "    libgcc-ng-15.1.0           |       h69a702a_2          34 KB  conda-forge\n",
            "    libgomp-15.1.0             |       h767d61c_2         442 KB  conda-forge\n",
            "    liblzma-5.8.1              |       hb9d3cd8_1         110 KB  conda-forge\n",
            "    libsqlite-3.49.2           |       hee588c1_0         895 KB  conda-forge\n",
            "    ncurses-6.5                |       h2d0b736_3         871 KB  conda-forge\n",
            "    pip-25.1.1                 |     pyh8b19718_0         1.2 MB  conda-forge\n",
            "    python-3.9.22              |h85ef794_1_cpython        22.5 MB  conda-forge\n",
            "    readline-8.2               |       h8c095d6_2         276 KB  conda-forge\n",
            "    setuptools-80.1.0          |     pyhff2d567_0         760 KB  conda-forge\n",
            "    tzdata-2025b               |       h78e105d_0         120 KB  conda-forge\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:        28.7 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  _libgcc_mutex      conda-forge/linux-64::_libgcc_mutex-0.1-conda_forge \n",
            "  _openmp_mutex      conda-forge/linux-64::_openmp_mutex-4.5-2_gnu \n",
            "  bzip2              conda-forge/linux-64::bzip2-1.0.8-h4bc722e_7 \n",
            "  ca-certificates    conda-forge/noarch::ca-certificates-2025.4.26-hbd8a1cb_0 \n",
            "  ld_impl_linux-64   conda-forge/linux-64::ld_impl_linux-64-2.43-h712a8e2_4 \n",
            "  libexpat           conda-forge/linux-64::libexpat-2.7.0-h5888daf_0 \n",
            "  libffi             conda-forge/linux-64::libffi-3.4.6-h2dba641_1 \n",
            "  libgcc             conda-forge/linux-64::libgcc-15.1.0-h767d61c_2 \n",
            "  libgcc-ng          conda-forge/linux-64::libgcc-ng-15.1.0-h69a702a_2 \n",
            "  libgomp            conda-forge/linux-64::libgomp-15.1.0-h767d61c_2 \n",
            "  liblzma            conda-forge/linux-64::liblzma-5.8.1-hb9d3cd8_1 \n",
            "  libnsl             conda-forge/linux-64::libnsl-2.0.1-hd590300_0 \n",
            "  libsqlite          conda-forge/linux-64::libsqlite-3.49.2-hee588c1_0 \n",
            "  libuuid            conda-forge/linux-64::libuuid-2.38.1-h0b41bf4_0 \n",
            "  libxcrypt          conda-forge/linux-64::libxcrypt-4.4.36-hd590300_1 \n",
            "  libzlib            conda-forge/linux-64::libzlib-1.3.1-hb9d3cd8_2 \n",
            "  ncurses            conda-forge/linux-64::ncurses-6.5-h2d0b736_3 \n",
            "  openssl            conda-forge/linux-64::openssl-3.5.0-h7b32b05_1 \n",
            "  pip                conda-forge/noarch::pip-25.1.1-pyh8b19718_0 \n",
            "  python             conda-forge/linux-64::python-3.9.22-h85ef794_1_cpython \n",
            "  readline           conda-forge/linux-64::readline-8.2-h8c095d6_2 \n",
            "  setuptools         conda-forge/noarch::setuptools-80.1.0-pyhff2d567_0 \n",
            "  tk                 conda-forge/linux-64::tk-8.6.13-noxft_h4845f30_101 \n",
            "  tzdata             conda-forge/noarch::tzdata-2025b-h78e105d_0 \n",
            "  wheel              conda-forge/noarch::wheel-0.45.1-pyhd8ed1ab_1 \n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages:\n",
            "python-3.9.22        | 22.5 MB   | :   0% 0/1 [00:00<?, ?it/s]\n",
            "pip-25.1.1           | 1.2 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "libsqlite-3.49.2     | 895 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "ncurses-6.5          | 871 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libgcc-15.1.0        | 810 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "setuptools-80.1.0    | 760 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ld_impl_linux-64-2.4 | 656 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgomp-15.1.0       | 442 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "readline-8.2         | 276 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tzdata-2025b         | 120 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "liblzma-5.8.1        | 110 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libexpat-2.7.0       | 73 KB     | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libffi-3.4.6         | 56 KB     | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgcc-ng-15.1.0     | 34 KB     | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pip-25.1.1           | 1.2 MB    | :   3% 0.026362133395548656/1 [00:00<00:03,  3.93s/it]\u001b[A\n",
            "\n",
            "libsqlite-3.49.2     | 895 KB    | :   4% 0.03576070622156403/1 [00:00<00:02,  3.00s/it]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "python-3.9.22        | 22.5 MB   | :   0% 0.0027745286114584187/1 [00:00<00:40, 40.92s/it]\n",
            "\n",
            "\n",
            "\n",
            "libgcc-15.1.0        | 810 KB    | :   8% 0.0790439846196153/1 [00:00<00:01,  1.43s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libgcc-15.1.0        | 810 KB    | : 100% 1.0/1 [00:00<00:00,  1.43s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pip-25.1.1           | 1.2 MB    | : 100% 1.0/1 [00:00<00:00,  3.93s/it]                 \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "setuptools-80.1.0    | 760 KB    | :   2% 0.021046033059125172/1 [00:00<00:08,  9.09s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "ncurses-6.5          | 871 KB    | : 100% 1.0/1 [00:00<00:00,  5.54it/s]                 \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "ncurses-6.5          | 871 KB    | : 100% 1.0/1 [00:00<00:00,  5.54it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "libsqlite-3.49.2     | 895 KB    | : 100% 1.0/1 [00:00<00:00,  5.44it/s]                \u001b[A\u001b[A\n",
            "\n",
            "python-3.9.22        | 22.5 MB   | :  16% 0.1630035559231821/1 [00:00<00:00,  1.11s/it]   \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "setuptools-80.1.0    | 760 KB    | : 100% 1.0/1 [00:00<00:00,  9.09s/it]                 \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ld_impl_linux-64-2.4 | 656 KB    | :   2% 0.02440855729694297/1 [00:00<00:09,  9.32s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ld_impl_linux-64-2.4 | 656 KB    | : 100% 1.0/1 [00:00<00:00,  9.32s/it]                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "readline-8.2         | 276 KB    | :   6% 0.05800056641178136/1 [00:00<00:04,  4.39s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "readline-8.2         | 276 KB    | : 100% 1.0/1 [00:00<00:00,  4.39s/it]                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tzdata-2025b         | 120 KB    | :  13% 0.1332379155552664/1 [00:00<00:01,  1.98s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tzdata-2025b         | 120 KB    | : 100% 1.0/1 [00:00<00:00,  1.98s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgomp-15.1.0       | 442 KB    | :   4% 0.03619693572083467/1 [00:00<00:07,  7.79s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "liblzma-5.8.1        | 110 KB    | :  15% 0.1451903052860118/1 [00:00<00:01,  1.94s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "liblzma-5.8.1        | 110 KB    | : 100% 1.0/1 [00:00<00:00,  1.94s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.9.22        | 22.5 MB   | :  39% 0.3884340056041786/1 [00:00<00:00,  1.50it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libexpat-2.7.0       | 73 KB     | :  22% 0.22013516600158545/1 [00:00<00:01,  1.41s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libexpat-2.7.0       | 73 KB     | : 100% 1.0/1 [00:00<00:00,  1.41s/it]                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgcc-ng-15.1.0     | 34 KB     | :  47% 0.47371768923842017/1 [00:00<00:00,  1.46it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgcc-ng-15.1.0     | 34 KB     | : 100% 1.0/1 [00:00<00:00,  1.46it/s]                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libgcc-15.1.0        | 810 KB    | : 100% 1.0/1 [00:00<00:00,  3.16it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libgcc-15.1.0        | 810 KB    | : 100% 1.0/1 [00:00<00:00,  3.16it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libffi-3.4.6         | 56 KB     | :  29% 0.2852715337871955/1 [00:00<00:00,  1.20s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.9.22        | 22.5 MB   | :  98% 0.9766340712333634/1 [00:00<00:00,  2.35it/s]\n",
            "pip-25.1.1           | 1.2 MB    | : 100% 1.0/1 [00:00<00:00,  1.32it/s]\u001b[A\n",
            "pip-25.1.1           | 1.2 MB    | : 100% 1.0/1 [00:00<00:00,  1.32it/s]\u001b[A\n",
            "\n",
            "python-3.9.22        | 22.5 MB   | : 100% 1.0/1 [00:00<00:00,  2.35it/s]               \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "setuptools-80.1.0    | 760 KB    | : 100% 1.0/1 [00:01<00:00,  1.17s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "setuptools-80.1.0    | 760 KB    | : 100% 1.0/1 [00:01<00:00,  1.17s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ld_impl_linux-64-2.4 | 656 KB    | : 100% 1.0/1 [00:01<00:00,  1.22s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ld_impl_linux-64-2.4 | 656 KB    | : 100% 1.0/1 [00:01<00:00,  1.22s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "readline-8.2         | 276 KB    | : 100% 1.0/1 [00:01<00:00,  1.26s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "readline-8.2         | 276 KB    | : 100% 1.0/1 [00:01<00:00,  1.26s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tzdata-2025b         | 120 KB    | : 100% 1.0/1 [00:01<00:00,  1.67s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tzdata-2025b         | 120 KB    | : 100% 1.0/1 [00:01<00:00,  1.67s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "liblzma-5.8.1        | 110 KB    | : 100% 1.0/1 [00:01<00:00,  1.70s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "liblzma-5.8.1        | 110 KB    | : 100% 1.0/1 [00:01<00:00,  1.70s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgomp-15.1.0       | 442 KB    | : 100% 1.0/1 [00:01<00:00,  1.70s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgomp-15.1.0       | 442 KB    | : 100% 1.0/1 [00:01<00:00,  1.70s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libexpat-2.7.0       | 73 KB     | : 100% 1.0/1 [00:01<00:00,  1.80s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libexpat-2.7.0       | 73 KB     | : 100% 1.0/1 [00:01<00:00,  1.80s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgcc-ng-15.1.0     | 34 KB     | : 100% 1.0/1 [00:01<00:00,  2.01s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgcc-ng-15.1.0     | 34 KB     | : 100% 1.0/1 [00:01<00:00,  2.01s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libffi-3.4.6         | 56 KB     | : 100% 1.0/1 [00:01<00:00,  1.90s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libffi-3.4.6         | 56 KB     | : 100% 1.0/1 [00:01<00:00,  1.90s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "                                                                        \n",
            "                                                                        \u001b[A\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Preparing transaction: - \b\b\\ \b\b| \b\bdone\n",
            "Verifying transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Executing transaction: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "#\n",
            "# To activate this environment, use\n",
            "#\n",
            "#     $ conda activate rformer\n",
            "#\n",
            "# To deactivate an active environment, use\n",
            "#\n",
            "#     $ conda deactivate\n",
            "\n",
            "Python 3.9.22\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Create a new environment named rformer with Python 3.9, for example\n",
        "!conda create -n rformer python=3.9 -y\n",
        "\n",
        "# Use packages within the environment directly\n",
        "# You can't \"activate\", but you can run commands inside the env like this:\n",
        "!conda run -n rformer python --version\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4uAnmmrhLSVf",
        "outputId": "3192665c-6694-4e09-a4d8-e0b3a1e64ca9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "other  UEA\n"
          ]
        }
      ],
      "source": [
        "os.chdir(\"src\")\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "6ozWie0YNWtO"
      },
      "outputs": [],
      "source": [
        "import torch as torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "249yeqBCNImw",
        "outputId": "87c7b2ef-1610-4440-832b-55516e12f840"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Torch Version: 2.7.0+cu126\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose \"Don't visualize my results\"\n",
            "Using device: cuda\n",
            "############### Config ###############\n",
            "{'accuracy_for_convergence': 0.6,\n",
            " 'add_time': True,\n",
            " 'attn_pdrop': 0.1,\n",
            " 'batch_size': 20,\n",
            " 'continue_training': False,\n",
            " 'dataset': 'TSC_SelfRegulationSCP1',\n",
            " 'downsampling': False,\n",
            " 'early_stop_ep': 500,\n",
            " 'embd_pdrop': 0.1,\n",
            " 'embedded_dim': 10,\n",
            " 'epoch': 110,\n",
            " 'epochs_for_convergence': 10000,\n",
            " 'eval_batch_size': -1,\n",
            " 'global_backward': True,\n",
            " 'global_forward': False,\n",
            " 'input_size': 5,\n",
            " 'irreg': True,\n",
            " 'local_tight': False,\n",
            " 'local_wide': False,\n",
            " 'local_width': 50,\n",
            " 'lr': 0.00040788,\n",
            " 'model': 'transformer',\n",
            " 'n_head': 3,\n",
            " 'n_seeds': 5,\n",
            " 'num_layers': 2,\n",
            " 'num_windows': 100,\n",
            " 'online_signature_calc': False,\n",
            " 'optimizer': 'Adam',\n",
            " 'overlap': False,\n",
            " 'pretrained_model_path': '',\n",
            " 'q_len': 1,\n",
            " 'random_percentage': 0.7,\n",
            " 'resid_pdrop': 0.1,\n",
            " 'save_all_epochs': False,\n",
            " 'scale_att': False,\n",
            " 'sig_level': 2,\n",
            " 'sig_win_len': 50,\n",
            " 'sparse': False,\n",
            " 'std_for_convergence': 0.05,\n",
            " 'sub_len': 1,\n",
            " 'test_size': 0.3,\n",
            " 'univariate': True,\n",
            " 'use_random_drop': False,\n",
            " 'use_signatures': True,\n",
            " 'v_partition': 0.1,\n",
            " 'val_size': 0.5,\n",
            " 'wandb': False,\n",
            " 'warmup_proportion': -1,\n",
            " 'weight_decay': 0,\n",
            " 'zero_shot_downsample': False}\n",
            "\n",
            "Seed: 42\n",
            "\n",
            "######################################\n",
            "Num features without signature:  6 Num features with signatures:  36\n",
            "Sequence length without signature:  896 Sequence length with signatures:  100\n",
            "\n",
            "Compression: 0.6696428571428571\n",
            "\n",
            "Compression L^2d: 0.07473692602040816\n",
            "\n",
            "Number of classes: 2\n",
            "---- Attn\n",
            "Query_Key_CNN: 12972\n",
            "Value_CNN: 6486\n",
            "C_proj_CNN: 6394\n",
            "--- Block\n",
            "attn: 25852\n",
            "mlp: 17158\n",
            "-- Transformer\n",
            "blocks: 86388\n",
            "po_embed: 1000\n",
            "-Decoder Transformer\n",
            "mlp: 94\n",
            "transformer: 87388\n",
            "Epoch 1/110, Loss: 0.6705, Valid Accuracy: 68.24%, Best Valid Accuracy: 68.24%, Test accuracy: 69.05%\n",
            "Epoch 2/110, Loss: 0.5048, Valid Accuracy: 83.53%, Best Valid Accuracy: 83.53%, Test accuracy: 72.62%\n",
            "Epoch 3/110, Loss: 0.8648, Valid Accuracy: 81.18%, Best Valid Accuracy: 83.53%, Test accuracy: 72.62%\n",
            "Epoch 4/110, Loss: 0.5918, Valid Accuracy: 81.18%, Best Valid Accuracy: 83.53%, Test accuracy: 76.19%\n",
            "Epoch 5/110, Loss: 0.1416, Valid Accuracy: 81.18%, Best Valid Accuracy: 83.53%, Test accuracy: 76.19%\n",
            "Epoch 6/110, Loss: 0.5180, Valid Accuracy: 85.88%, Best Valid Accuracy: 85.88%, Test accuracy: 73.81%\n",
            "Epoch 7/110, Loss: 0.5822, Valid Accuracy: 84.71%, Best Valid Accuracy: 85.88%, Test accuracy: 77.38%\n",
            "Epoch 8/110, Loss: 0.3132, Valid Accuracy: 87.06%, Best Valid Accuracy: 87.06%, Test accuracy: 77.38%\n",
            "Epoch 9/110, Loss: 0.8097, Valid Accuracy: 83.53%, Best Valid Accuracy: 87.06%, Test accuracy: 73.81%\n",
            "Epoch 10/110, Loss: 0.5485, Valid Accuracy: 84.71%, Best Valid Accuracy: 87.06%, Test accuracy: 72.62%\n",
            "Epoch 11/110, Loss: 0.2963, Valid Accuracy: 85.88%, Best Valid Accuracy: 87.06%, Test accuracy: 76.19%\n",
            "Epoch 12/110, Loss: 0.3252, Valid Accuracy: 84.71%, Best Valid Accuracy: 87.06%, Test accuracy: 78.57%\n",
            "Epoch 13/110, Loss: 0.4531, Valid Accuracy: 85.88%, Best Valid Accuracy: 87.06%, Test accuracy: 72.62%\n",
            "Epoch 14/110, Loss: 0.4810, Valid Accuracy: 87.06%, Best Valid Accuracy: 87.06%, Test accuracy: 73.81%\n",
            "Epoch 15/110, Loss: 0.4697, Valid Accuracy: 87.06%, Best Valid Accuracy: 87.06%, Test accuracy: 72.62%\n",
            "Epoch 16/110, Loss: 0.3852, Valid Accuracy: 82.35%, Best Valid Accuracy: 87.06%, Test accuracy: 71.43%\n",
            "Epoch 17/110, Loss: 0.6068, Valid Accuracy: 88.24%, Best Valid Accuracy: 88.24%, Test accuracy: 76.19%\n",
            "Epoch 18/110, Loss: 0.4635, Valid Accuracy: 87.06%, Best Valid Accuracy: 88.24%, Test accuracy: 77.38%\n",
            "Epoch 19/110, Loss: 0.7243, Valid Accuracy: 89.41%, Best Valid Accuracy: 89.41%, Test accuracy: 76.19%\n",
            "Epoch 20/110, Loss: 0.4699, Valid Accuracy: 89.41%, Best Valid Accuracy: 89.41%, Test accuracy: 76.19%\n",
            "Epoch 21/110, Loss: 0.4742, Valid Accuracy: 90.59%, Best Valid Accuracy: 90.59%, Test accuracy: 78.57%\n",
            "Epoch 22/110, Loss: 0.0876, Valid Accuracy: 88.24%, Best Valid Accuracy: 90.59%, Test accuracy: 75.00%\n",
            "Epoch 23/110, Loss: 0.2833, Valid Accuracy: 87.06%, Best Valid Accuracy: 90.59%, Test accuracy: 78.57%\n",
            "Epoch 24/110, Loss: 0.5457, Valid Accuracy: 90.59%, Best Valid Accuracy: 90.59%, Test accuracy: 76.19%\n",
            "Epoch 25/110, Loss: 0.4410, Valid Accuracy: 88.24%, Best Valid Accuracy: 90.59%, Test accuracy: 73.81%\n",
            "Epoch 26/110, Loss: 0.1547, Valid Accuracy: 84.71%, Best Valid Accuracy: 90.59%, Test accuracy: 77.38%\n",
            "Epoch 27/110, Loss: 0.3068, Valid Accuracy: 87.06%, Best Valid Accuracy: 90.59%, Test accuracy: 76.19%\n",
            "Epoch 28/110, Loss: 0.2010, Valid Accuracy: 87.06%, Best Valid Accuracy: 90.59%, Test accuracy: 75.00%\n",
            "Epoch 29/110, Loss: 0.2703, Valid Accuracy: 87.06%, Best Valid Accuracy: 90.59%, Test accuracy: 78.57%\n",
            "Epoch 30/110, Loss: 0.1253, Valid Accuracy: 87.06%, Best Valid Accuracy: 90.59%, Test accuracy: 77.38%\n",
            "Epoch 31/110, Loss: 0.2578, Valid Accuracy: 87.06%, Best Valid Accuracy: 90.59%, Test accuracy: 76.19%\n",
            "Epoch 32/110, Loss: 0.2900, Valid Accuracy: 88.24%, Best Valid Accuracy: 90.59%, Test accuracy: 75.00%\n",
            "Epoch 33/110, Loss: 0.4516, Valid Accuracy: 85.88%, Best Valid Accuracy: 90.59%, Test accuracy: 77.38%\n",
            "Epoch 34/110, Loss: 0.2627, Valid Accuracy: 88.24%, Best Valid Accuracy: 90.59%, Test accuracy: 77.38%\n",
            "Epoch 35/110, Loss: 0.2807, Valid Accuracy: 88.24%, Best Valid Accuracy: 90.59%, Test accuracy: 77.38%\n",
            "Epoch 36/110, Loss: 0.8337, Valid Accuracy: 83.53%, Best Valid Accuracy: 90.59%, Test accuracy: 75.00%\n",
            "Epoch 37/110, Loss: 0.1447, Valid Accuracy: 85.88%, Best Valid Accuracy: 90.59%, Test accuracy: 80.95%\n",
            "Epoch 38/110, Loss: 0.2713, Valid Accuracy: 88.24%, Best Valid Accuracy: 90.59%, Test accuracy: 76.19%\n",
            "Epoch 39/110, Loss: 0.3487, Valid Accuracy: 88.24%, Best Valid Accuracy: 90.59%, Test accuracy: 77.38%\n",
            "Epoch 40/110, Loss: 0.1603, Valid Accuracy: 90.59%, Best Valid Accuracy: 90.59%, Test accuracy: 77.38%\n",
            "Epoch 41/110, Loss: 0.2607, Valid Accuracy: 90.59%, Best Valid Accuracy: 90.59%, Test accuracy: 78.57%\n",
            "Epoch 42/110, Loss: 0.6134, Valid Accuracy: 91.76%, Best Valid Accuracy: 91.76%, Test accuracy: 78.57%\n",
            "Epoch 43/110, Loss: 0.1630, Valid Accuracy: 90.59%, Best Valid Accuracy: 91.76%, Test accuracy: 78.57%\n",
            "Epoch 44/110, Loss: 0.3313, Valid Accuracy: 92.94%, Best Valid Accuracy: 92.94%, Test accuracy: 79.76%\n",
            "Epoch 45/110, Loss: 0.1534, Valid Accuracy: 91.76%, Best Valid Accuracy: 92.94%, Test accuracy: 77.38%\n",
            "Epoch 46/110, Loss: 0.0856, Valid Accuracy: 95.29%, Best Valid Accuracy: 95.29%, Test accuracy: 82.14%\n",
            "Epoch 47/110, Loss: 0.3161, Valid Accuracy: 94.12%, Best Valid Accuracy: 95.29%, Test accuracy: 76.19%\n",
            "Epoch 48/110, Loss: 0.2808, Valid Accuracy: 90.59%, Best Valid Accuracy: 95.29%, Test accuracy: 75.00%\n",
            "Epoch 49/110, Loss: 0.2591, Valid Accuracy: 94.12%, Best Valid Accuracy: 95.29%, Test accuracy: 79.76%\n",
            "Epoch 50/110, Loss: 0.3006, Valid Accuracy: 94.12%, Best Valid Accuracy: 95.29%, Test accuracy: 78.57%\n",
            "Epoch 51/110, Loss: 0.1548, Valid Accuracy: 90.59%, Best Valid Accuracy: 95.29%, Test accuracy: 80.95%\n",
            "Epoch 52/110, Loss: 0.1446, Valid Accuracy: 91.76%, Best Valid Accuracy: 95.29%, Test accuracy: 79.76%\n",
            "Epoch 53/110, Loss: 0.0679, Valid Accuracy: 91.76%, Best Valid Accuracy: 95.29%, Test accuracy: 76.19%\n",
            "Epoch 54/110, Loss: 0.0353, Valid Accuracy: 88.24%, Best Valid Accuracy: 95.29%, Test accuracy: 76.19%\n",
            "Epoch 55/110, Loss: 0.3936, Valid Accuracy: 89.41%, Best Valid Accuracy: 95.29%, Test accuracy: 72.62%\n",
            "Epoch 56/110, Loss: 0.2196, Valid Accuracy: 91.76%, Best Valid Accuracy: 95.29%, Test accuracy: 76.19%\n",
            "Epoch 57/110, Loss: 0.0801, Valid Accuracy: 87.06%, Best Valid Accuracy: 95.29%, Test accuracy: 75.00%\n",
            "Epoch 58/110, Loss: 0.1253, Valid Accuracy: 90.59%, Best Valid Accuracy: 95.29%, Test accuracy: 77.38%\n",
            "Epoch 59/110, Loss: 0.2336, Valid Accuracy: 88.24%, Best Valid Accuracy: 95.29%, Test accuracy: 76.19%\n",
            "Epoch 60/110, Loss: 0.2208, Valid Accuracy: 88.24%, Best Valid Accuracy: 95.29%, Test accuracy: 76.19%\n",
            "Epoch 61/110, Loss: 0.1785, Valid Accuracy: 87.06%, Best Valid Accuracy: 95.29%, Test accuracy: 78.57%\n",
            "Epoch 62/110, Loss: 0.2197, Valid Accuracy: 88.24%, Best Valid Accuracy: 95.29%, Test accuracy: 77.38%\n",
            "Epoch 63/110, Loss: 0.1117, Valid Accuracy: 89.41%, Best Valid Accuracy: 95.29%, Test accuracy: 77.38%\n",
            "Epoch 64/110, Loss: 0.1307, Valid Accuracy: 85.88%, Best Valid Accuracy: 95.29%, Test accuracy: 78.57%\n",
            "Epoch 65/110, Loss: 0.4614, Valid Accuracy: 85.88%, Best Valid Accuracy: 95.29%, Test accuracy: 77.38%\n",
            "Epoch 66/110, Loss: 0.1826, Valid Accuracy: 81.18%, Best Valid Accuracy: 95.29%, Test accuracy: 71.43%\n",
            "Epoch 67/110, Loss: 0.1521, Valid Accuracy: 81.18%, Best Valid Accuracy: 95.29%, Test accuracy: 75.00%\n",
            "Epoch 68/110, Loss: 0.2443, Valid Accuracy: 89.41%, Best Valid Accuracy: 95.29%, Test accuracy: 79.76%\n",
            "Epoch 69/110, Loss: 0.3167, Valid Accuracy: 85.88%, Best Valid Accuracy: 95.29%, Test accuracy: 78.57%\n",
            "Epoch 70/110, Loss: 0.1456, Valid Accuracy: 90.59%, Best Valid Accuracy: 95.29%, Test accuracy: 79.76%\n",
            "Epoch 71/110, Loss: 0.1406, Valid Accuracy: 88.24%, Best Valid Accuracy: 95.29%, Test accuracy: 80.95%\n",
            "Epoch 72/110, Loss: 0.0489, Valid Accuracy: 90.59%, Best Valid Accuracy: 95.29%, Test accuracy: 79.76%\n",
            "Epoch 73/110, Loss: 0.1765, Valid Accuracy: 88.24%, Best Valid Accuracy: 95.29%, Test accuracy: 80.95%\n",
            "Epoch 74/110, Loss: 0.1264, Valid Accuracy: 88.24%, Best Valid Accuracy: 95.29%, Test accuracy: 83.33%\n",
            "Epoch 75/110, Loss: 0.0307, Valid Accuracy: 84.71%, Best Valid Accuracy: 95.29%, Test accuracy: 76.19%\n",
            "Epoch 76/110, Loss: 0.0977, Valid Accuracy: 83.53%, Best Valid Accuracy: 95.29%, Test accuracy: 76.19%\n",
            "Epoch 77/110, Loss: 0.0836, Valid Accuracy: 82.35%, Best Valid Accuracy: 95.29%, Test accuracy: 75.00%\n",
            "Epoch 78/110, Loss: 0.0882, Valid Accuracy: 89.41%, Best Valid Accuracy: 95.29%, Test accuracy: 76.19%\n",
            "Epoch 79/110, Loss: 0.0455, Valid Accuracy: 87.06%, Best Valid Accuracy: 95.29%, Test accuracy: 76.19%\n",
            "Epoch 80/110, Loss: 0.1090, Valid Accuracy: 83.53%, Best Valid Accuracy: 95.29%, Test accuracy: 78.57%\n",
            "Epoch 81/110, Loss: 0.1373, Valid Accuracy: 84.71%, Best Valid Accuracy: 95.29%, Test accuracy: 76.19%\n",
            "Epoch 82/110, Loss: 0.2254, Valid Accuracy: 80.00%, Best Valid Accuracy: 95.29%, Test accuracy: 77.38%\n",
            "Epoch 83/110, Loss: 0.4403, Valid Accuracy: 82.35%, Best Valid Accuracy: 95.29%, Test accuracy: 77.38%\n",
            "Epoch 84/110, Loss: 0.0567, Valid Accuracy: 87.06%, Best Valid Accuracy: 95.29%, Test accuracy: 76.19%\n",
            "Epoch 85/110, Loss: 0.2191, Valid Accuracy: 84.71%, Best Valid Accuracy: 95.29%, Test accuracy: 77.38%\n",
            "Epoch 86/110, Loss: 0.0616, Valid Accuracy: 83.53%, Best Valid Accuracy: 95.29%, Test accuracy: 75.00%\n",
            "Epoch 87/110, Loss: 0.0540, Valid Accuracy: 81.18%, Best Valid Accuracy: 95.29%, Test accuracy: 78.57%\n",
            "Epoch 88/110, Loss: 0.0236, Valid Accuracy: 85.88%, Best Valid Accuracy: 95.29%, Test accuracy: 78.57%\n",
            "Epoch 89/110, Loss: 0.0237, Valid Accuracy: 87.06%, Best Valid Accuracy: 95.29%, Test accuracy: 76.19%\n",
            "Epoch 90/110, Loss: 0.1888, Valid Accuracy: 85.88%, Best Valid Accuracy: 95.29%, Test accuracy: 76.19%\n",
            "Epoch 91/110, Loss: 0.0681, Valid Accuracy: 84.71%, Best Valid Accuracy: 95.29%, Test accuracy: 73.81%\n",
            "Epoch 92/110, Loss: 0.0613, Valid Accuracy: 84.71%, Best Valid Accuracy: 95.29%, Test accuracy: 78.57%\n",
            "Epoch 93/110, Loss: 0.3550, Valid Accuracy: 80.00%, Best Valid Accuracy: 95.29%, Test accuracy: 73.81%\n",
            "Epoch 94/110, Loss: 0.0311, Valid Accuracy: 87.06%, Best Valid Accuracy: 95.29%, Test accuracy: 76.19%\n",
            "Epoch 95/110, Loss: 0.0825, Valid Accuracy: 84.71%, Best Valid Accuracy: 95.29%, Test accuracy: 79.76%\n",
            "Epoch 96/110, Loss: 0.0326, Valid Accuracy: 85.88%, Best Valid Accuracy: 95.29%, Test accuracy: 78.57%\n",
            "Epoch 97/110, Loss: 0.0263, Valid Accuracy: 85.88%, Best Valid Accuracy: 95.29%, Test accuracy: 77.38%\n",
            "Epoch 98/110, Loss: 0.0347, Valid Accuracy: 83.53%, Best Valid Accuracy: 95.29%, Test accuracy: 79.76%\n",
            "Epoch 99/110, Loss: 0.0720, Valid Accuracy: 83.53%, Best Valid Accuracy: 95.29%, Test accuracy: 78.57%\n",
            "Epoch 100/110, Loss: 0.0298, Valid Accuracy: 89.41%, Best Valid Accuracy: 95.29%, Test accuracy: 76.19%\n",
            "Epoch 101/110, Loss: 0.0964, Valid Accuracy: 88.24%, Best Valid Accuracy: 95.29%, Test accuracy: 79.76%\n",
            "Epoch 102/110, Loss: 0.0017, Valid Accuracy: 84.71%, Best Valid Accuracy: 95.29%, Test accuracy: 79.76%\n",
            "Epoch 103/110, Loss: 0.1606, Valid Accuracy: 87.06%, Best Valid Accuracy: 95.29%, Test accuracy: 76.19%\n",
            "Epoch 104/110, Loss: 0.1027, Valid Accuracy: 83.53%, Best Valid Accuracy: 95.29%, Test accuracy: 77.38%\n",
            "Epoch 105/110, Loss: 0.3188, Valid Accuracy: 84.71%, Best Valid Accuracy: 95.29%, Test accuracy: 77.38%\n",
            "Epoch 106/110, Loss: 0.0217, Valid Accuracy: 88.24%, Best Valid Accuracy: 95.29%, Test accuracy: 76.19%\n",
            "Epoch 107/110, Loss: 0.0192, Valid Accuracy: 85.88%, Best Valid Accuracy: 95.29%, Test accuracy: 73.81%\n",
            "Epoch 108/110, Loss: 0.0930, Valid Accuracy: 88.24%, Best Valid Accuracy: 95.29%, Test accuracy: 76.19%\n",
            "Epoch 109/110, Loss: 0.0019, Valid Accuracy: 84.71%, Best Valid Accuracy: 95.29%, Test accuracy: 76.19%\n",
            "Epoch 110/110, Loss: 0.0130, Valid Accuracy: 84.71%, Best Valid Accuracy: 95.29%, Test accuracy: 77.38%\n",
            "Training time: 26.98 seconds\n",
            "Total time: 30.76 seconds\n",
            "0.7738095238095238\n",
            "############### Config ###############\n",
            "{'accuracy_for_convergence': 0.6,\n",
            " 'add_time': True,\n",
            " 'attn_pdrop': 0.1,\n",
            " 'batch_size': 20,\n",
            " 'continue_training': False,\n",
            " 'dataset': 'TSC_SelfRegulationSCP1',\n",
            " 'downsampling': False,\n",
            " 'early_stop_ep': 500,\n",
            " 'embd_pdrop': 0.1,\n",
            " 'embedded_dim': 10,\n",
            " 'epoch': 110,\n",
            " 'epochs_for_convergence': 10000,\n",
            " 'eval_batch_size': -1,\n",
            " 'global_backward': True,\n",
            " 'global_forward': False,\n",
            " 'input_size': 5,\n",
            " 'irreg': True,\n",
            " 'local_tight': False,\n",
            " 'local_wide': False,\n",
            " 'local_width': 50,\n",
            " 'lr': 0.00040788,\n",
            " 'model': 'transformer',\n",
            " 'n_head': 3,\n",
            " 'n_seeds': 5,\n",
            " 'num_layers': 2,\n",
            " 'num_windows': 100,\n",
            " 'online_signature_calc': False,\n",
            " 'optimizer': 'Adam',\n",
            " 'overlap': False,\n",
            " 'pretrained_model_path': '',\n",
            " 'q_len': 1,\n",
            " 'random_percentage': 0.7,\n",
            " 'resid_pdrop': 0.1,\n",
            " 'save_all_epochs': False,\n",
            " 'scale_att': False,\n",
            " 'sig_level': 2,\n",
            " 'sig_win_len': 50,\n",
            " 'sparse': False,\n",
            " 'std_for_convergence': 0.05,\n",
            " 'sub_len': 1,\n",
            " 'test_size': 0.3,\n",
            " 'univariate': True,\n",
            " 'use_random_drop': False,\n",
            " 'use_signatures': True,\n",
            " 'v_partition': 0.1,\n",
            " 'val_size': 0.5,\n",
            " 'wandb': False,\n",
            " 'warmup_proportion': -1,\n",
            " 'weight_decay': 0,\n",
            " 'zero_shot_downsample': False}\n",
            "\n",
            "Seed: 43\n",
            "\n",
            "######################################\n",
            "Num features without signature:  6 Num features with signatures:  36\n",
            "Sequence length without signature:  896 Sequence length with signatures:  100\n",
            "\n",
            "Compression: 0.6696428571428571\n",
            "\n",
            "Compression L^2d: 0.07473692602040816\n",
            "\n",
            "Number of classes: 2\n",
            "---- Attn\n",
            "Query_Key_CNN: 12972\n",
            "Value_CNN: 6486\n",
            "C_proj_CNN: 6394\n",
            "--- Block\n",
            "attn: 25852\n",
            "mlp: 17158\n",
            "-- Transformer\n",
            "blocks: 86388\n",
            "po_embed: 1000\n",
            "-Decoder Transformer\n",
            "mlp: 94\n",
            "transformer: 87388\n",
            "Epoch 1/110, Loss: 0.6678, Valid Accuracy: 74.12%, Best Valid Accuracy: 74.12%, Test accuracy: 82.14%\n",
            "Epoch 2/110, Loss: 0.5168, Valid Accuracy: 77.65%, Best Valid Accuracy: 77.65%, Test accuracy: 79.76%\n",
            "Epoch 3/110, Loss: 0.7517, Valid Accuracy: 81.18%, Best Valid Accuracy: 81.18%, Test accuracy: 80.95%\n",
            "Epoch 4/110, Loss: 0.5067, Valid Accuracy: 80.00%, Best Valid Accuracy: 81.18%, Test accuracy: 79.76%\n",
            "Epoch 5/110, Loss: 0.3036, Valid Accuracy: 81.18%, Best Valid Accuracy: 81.18%, Test accuracy: 80.95%\n",
            "Epoch 6/110, Loss: 0.2510, Valid Accuracy: 78.82%, Best Valid Accuracy: 81.18%, Test accuracy: 82.14%\n",
            "Epoch 7/110, Loss: 0.2843, Valid Accuracy: 77.65%, Best Valid Accuracy: 81.18%, Test accuracy: 83.33%\n",
            "Epoch 8/110, Loss: 0.2908, Valid Accuracy: 78.82%, Best Valid Accuracy: 81.18%, Test accuracy: 83.33%\n",
            "Epoch 9/110, Loss: 0.1139, Valid Accuracy: 77.65%, Best Valid Accuracy: 81.18%, Test accuracy: 79.76%\n",
            "Epoch 10/110, Loss: 0.5098, Valid Accuracy: 80.00%, Best Valid Accuracy: 81.18%, Test accuracy: 80.95%\n",
            "Epoch 11/110, Loss: 0.1600, Valid Accuracy: 81.18%, Best Valid Accuracy: 81.18%, Test accuracy: 80.95%\n",
            "Epoch 12/110, Loss: 0.4257, Valid Accuracy: 78.82%, Best Valid Accuracy: 81.18%, Test accuracy: 84.52%\n",
            "Epoch 13/110, Loss: 0.7649, Valid Accuracy: 77.65%, Best Valid Accuracy: 81.18%, Test accuracy: 84.52%\n",
            "Epoch 14/110, Loss: 0.1940, Valid Accuracy: 78.82%, Best Valid Accuracy: 81.18%, Test accuracy: 80.95%\n",
            "Epoch 15/110, Loss: 0.3174, Valid Accuracy: 76.47%, Best Valid Accuracy: 81.18%, Test accuracy: 80.95%\n",
            "Epoch 16/110, Loss: 0.2949, Valid Accuracy: 76.47%, Best Valid Accuracy: 81.18%, Test accuracy: 79.76%\n",
            "Epoch 17/110, Loss: 0.1154, Valid Accuracy: 74.12%, Best Valid Accuracy: 81.18%, Test accuracy: 83.33%\n",
            "Epoch 18/110, Loss: 0.2580, Valid Accuracy: 77.65%, Best Valid Accuracy: 81.18%, Test accuracy: 86.90%\n",
            "Epoch 19/110, Loss: 0.4608, Valid Accuracy: 77.65%, Best Valid Accuracy: 81.18%, Test accuracy: 83.33%\n",
            "Epoch 20/110, Loss: 0.0833, Valid Accuracy: 80.00%, Best Valid Accuracy: 81.18%, Test accuracy: 83.33%\n",
            "Epoch 21/110, Loss: 0.1918, Valid Accuracy: 76.47%, Best Valid Accuracy: 81.18%, Test accuracy: 78.57%\n",
            "Epoch 22/110, Loss: 0.3940, Valid Accuracy: 76.47%, Best Valid Accuracy: 81.18%, Test accuracy: 82.14%\n",
            "Epoch 23/110, Loss: 0.1436, Valid Accuracy: 78.82%, Best Valid Accuracy: 81.18%, Test accuracy: 83.33%\n",
            "Epoch 24/110, Loss: 0.2781, Valid Accuracy: 80.00%, Best Valid Accuracy: 81.18%, Test accuracy: 83.33%\n",
            "Epoch 25/110, Loss: 0.5287, Valid Accuracy: 80.00%, Best Valid Accuracy: 81.18%, Test accuracy: 84.52%\n",
            "Epoch 26/110, Loss: 0.1792, Valid Accuracy: 77.65%, Best Valid Accuracy: 81.18%, Test accuracy: 82.14%\n",
            "Epoch 27/110, Loss: 0.1213, Valid Accuracy: 78.82%, Best Valid Accuracy: 81.18%, Test accuracy: 82.14%\n",
            "Epoch 28/110, Loss: 0.0751, Valid Accuracy: 80.00%, Best Valid Accuracy: 81.18%, Test accuracy: 83.33%\n",
            "Epoch 29/110, Loss: 0.1114, Valid Accuracy: 81.18%, Best Valid Accuracy: 81.18%, Test accuracy: 85.71%\n",
            "Epoch 30/110, Loss: 0.6403, Valid Accuracy: 81.18%, Best Valid Accuracy: 81.18%, Test accuracy: 82.14%\n",
            "Epoch 31/110, Loss: 0.1506, Valid Accuracy: 81.18%, Best Valid Accuracy: 81.18%, Test accuracy: 83.33%\n",
            "Epoch 32/110, Loss: 0.1878, Valid Accuracy: 78.82%, Best Valid Accuracy: 81.18%, Test accuracy: 82.14%\n",
            "Epoch 33/110, Loss: 0.0593, Valid Accuracy: 81.18%, Best Valid Accuracy: 81.18%, Test accuracy: 83.33%\n",
            "Epoch 34/110, Loss: 0.2703, Valid Accuracy: 80.00%, Best Valid Accuracy: 81.18%, Test accuracy: 85.71%\n",
            "Epoch 35/110, Loss: 0.3098, Valid Accuracy: 78.82%, Best Valid Accuracy: 81.18%, Test accuracy: 83.33%\n",
            "Epoch 36/110, Loss: 0.0544, Valid Accuracy: 76.47%, Best Valid Accuracy: 81.18%, Test accuracy: 83.33%\n",
            "Epoch 37/110, Loss: 0.1573, Valid Accuracy: 77.65%, Best Valid Accuracy: 81.18%, Test accuracy: 84.52%\n",
            "Epoch 38/110, Loss: 0.0553, Valid Accuracy: 77.65%, Best Valid Accuracy: 81.18%, Test accuracy: 83.33%\n",
            "Epoch 39/110, Loss: 0.3888, Valid Accuracy: 75.29%, Best Valid Accuracy: 81.18%, Test accuracy: 86.90%\n",
            "Epoch 40/110, Loss: 0.1001, Valid Accuracy: 76.47%, Best Valid Accuracy: 81.18%, Test accuracy: 82.14%\n",
            "Epoch 41/110, Loss: 0.1716, Valid Accuracy: 76.47%, Best Valid Accuracy: 81.18%, Test accuracy: 84.52%\n",
            "Epoch 42/110, Loss: 0.1229, Valid Accuracy: 80.00%, Best Valid Accuracy: 81.18%, Test accuracy: 79.76%\n",
            "Epoch 43/110, Loss: 0.0388, Valid Accuracy: 77.65%, Best Valid Accuracy: 81.18%, Test accuracy: 80.95%\n",
            "Epoch 44/110, Loss: 0.1072, Valid Accuracy: 77.65%, Best Valid Accuracy: 81.18%, Test accuracy: 82.14%\n",
            "Epoch 45/110, Loss: 0.1545, Valid Accuracy: 75.29%, Best Valid Accuracy: 81.18%, Test accuracy: 80.95%\n",
            "Epoch 46/110, Loss: 0.3098, Valid Accuracy: 74.12%, Best Valid Accuracy: 81.18%, Test accuracy: 75.00%\n",
            "Epoch 47/110, Loss: 0.0127, Valid Accuracy: 72.94%, Best Valid Accuracy: 81.18%, Test accuracy: 84.52%\n",
            "Epoch 48/110, Loss: 0.2466, Valid Accuracy: 76.47%, Best Valid Accuracy: 81.18%, Test accuracy: 82.14%\n",
            "Epoch 49/110, Loss: 0.0522, Valid Accuracy: 75.29%, Best Valid Accuracy: 81.18%, Test accuracy: 82.14%\n",
            "Epoch 50/110, Loss: 0.1012, Valid Accuracy: 75.29%, Best Valid Accuracy: 81.18%, Test accuracy: 84.52%\n",
            "Epoch 51/110, Loss: 0.0802, Valid Accuracy: 78.82%, Best Valid Accuracy: 81.18%, Test accuracy: 80.95%\n",
            "Epoch 52/110, Loss: 0.0977, Valid Accuracy: 74.12%, Best Valid Accuracy: 81.18%, Test accuracy: 78.57%\n",
            "Epoch 53/110, Loss: 0.0242, Valid Accuracy: 77.65%, Best Valid Accuracy: 81.18%, Test accuracy: 84.52%\n",
            "Epoch 54/110, Loss: 0.1498, Valid Accuracy: 77.65%, Best Valid Accuracy: 81.18%, Test accuracy: 83.33%\n",
            "Epoch 55/110, Loss: 0.0752, Valid Accuracy: 78.82%, Best Valid Accuracy: 81.18%, Test accuracy: 82.14%\n",
            "Epoch 56/110, Loss: 0.0946, Valid Accuracy: 81.18%, Best Valid Accuracy: 81.18%, Test accuracy: 84.52%\n",
            "Epoch 57/110, Loss: 0.0537, Valid Accuracy: 77.65%, Best Valid Accuracy: 81.18%, Test accuracy: 82.14%\n",
            "Epoch 58/110, Loss: 0.0183, Valid Accuracy: 78.82%, Best Valid Accuracy: 81.18%, Test accuracy: 79.76%\n",
            "Epoch 59/110, Loss: 0.0220, Valid Accuracy: 76.47%, Best Valid Accuracy: 81.18%, Test accuracy: 82.14%\n",
            "Epoch 60/110, Loss: 0.0784, Valid Accuracy: 80.00%, Best Valid Accuracy: 81.18%, Test accuracy: 79.76%\n",
            "Epoch 61/110, Loss: 0.3025, Valid Accuracy: 82.35%, Best Valid Accuracy: 82.35%, Test accuracy: 84.52%\n",
            "Epoch 62/110, Loss: 0.0240, Valid Accuracy: 76.47%, Best Valid Accuracy: 82.35%, Test accuracy: 80.95%\n",
            "Epoch 63/110, Loss: 0.0581, Valid Accuracy: 81.18%, Best Valid Accuracy: 82.35%, Test accuracy: 82.14%\n",
            "Epoch 64/110, Loss: 0.0089, Valid Accuracy: 80.00%, Best Valid Accuracy: 82.35%, Test accuracy: 82.14%\n",
            "Epoch 65/110, Loss: 0.0117, Valid Accuracy: 78.82%, Best Valid Accuracy: 82.35%, Test accuracy: 83.33%\n",
            "Epoch 66/110, Loss: 0.0349, Valid Accuracy: 76.47%, Best Valid Accuracy: 82.35%, Test accuracy: 85.71%\n",
            "Epoch 67/110, Loss: 0.0434, Valid Accuracy: 76.47%, Best Valid Accuracy: 82.35%, Test accuracy: 83.33%\n",
            "Epoch 68/110, Loss: 0.0044, Valid Accuracy: 77.65%, Best Valid Accuracy: 82.35%, Test accuracy: 79.76%\n",
            "Epoch 69/110, Loss: 0.0275, Valid Accuracy: 78.82%, Best Valid Accuracy: 82.35%, Test accuracy: 82.14%\n",
            "Epoch 70/110, Loss: 0.1399, Valid Accuracy: 78.82%, Best Valid Accuracy: 82.35%, Test accuracy: 82.14%\n",
            "Epoch 71/110, Loss: 0.1290, Valid Accuracy: 81.18%, Best Valid Accuracy: 82.35%, Test accuracy: 79.76%\n",
            "Epoch 72/110, Loss: 0.0833, Valid Accuracy: 76.47%, Best Valid Accuracy: 82.35%, Test accuracy: 78.57%\n",
            "Epoch 73/110, Loss: 0.3839, Valid Accuracy: 76.47%, Best Valid Accuracy: 82.35%, Test accuracy: 79.76%\n",
            "Epoch 74/110, Loss: 0.4283, Valid Accuracy: 76.47%, Best Valid Accuracy: 82.35%, Test accuracy: 80.95%\n",
            "Epoch 75/110, Loss: 0.0489, Valid Accuracy: 81.18%, Best Valid Accuracy: 82.35%, Test accuracy: 80.95%\n",
            "Epoch 76/110, Loss: 0.0145, Valid Accuracy: 76.47%, Best Valid Accuracy: 82.35%, Test accuracy: 80.95%\n",
            "Epoch 77/110, Loss: 0.2429, Valid Accuracy: 76.47%, Best Valid Accuracy: 82.35%, Test accuracy: 80.95%\n",
            "Epoch 78/110, Loss: 0.0305, Valid Accuracy: 76.47%, Best Valid Accuracy: 82.35%, Test accuracy: 79.76%\n",
            "Epoch 79/110, Loss: 0.0310, Valid Accuracy: 77.65%, Best Valid Accuracy: 82.35%, Test accuracy: 79.76%\n",
            "Epoch 80/110, Loss: 0.2288, Valid Accuracy: 80.00%, Best Valid Accuracy: 82.35%, Test accuracy: 79.76%\n",
            "Epoch 81/110, Loss: 0.0086, Valid Accuracy: 81.18%, Best Valid Accuracy: 82.35%, Test accuracy: 83.33%\n",
            "Epoch 82/110, Loss: 0.0318, Valid Accuracy: 75.29%, Best Valid Accuracy: 82.35%, Test accuracy: 82.14%\n",
            "Epoch 83/110, Loss: 0.1891, Valid Accuracy: 80.00%, Best Valid Accuracy: 82.35%, Test accuracy: 83.33%\n",
            "Epoch 84/110, Loss: 0.0972, Valid Accuracy: 75.29%, Best Valid Accuracy: 82.35%, Test accuracy: 83.33%\n",
            "Epoch 85/110, Loss: 0.0058, Valid Accuracy: 77.65%, Best Valid Accuracy: 82.35%, Test accuracy: 84.52%\n",
            "Epoch 86/110, Loss: 0.0208, Valid Accuracy: 76.47%, Best Valid Accuracy: 82.35%, Test accuracy: 84.52%\n",
            "Epoch 87/110, Loss: 0.1530, Valid Accuracy: 78.82%, Best Valid Accuracy: 82.35%, Test accuracy: 84.52%\n",
            "Epoch 88/110, Loss: 0.0283, Valid Accuracy: 77.65%, Best Valid Accuracy: 82.35%, Test accuracy: 82.14%\n",
            "Epoch 89/110, Loss: 0.0923, Valid Accuracy: 80.00%, Best Valid Accuracy: 82.35%, Test accuracy: 83.33%\n",
            "Epoch 90/110, Loss: 0.0220, Valid Accuracy: 81.18%, Best Valid Accuracy: 82.35%, Test accuracy: 79.76%\n",
            "Epoch 91/110, Loss: 0.2072, Valid Accuracy: 82.35%, Best Valid Accuracy: 82.35%, Test accuracy: 78.57%\n",
            "Epoch 92/110, Loss: 0.0538, Valid Accuracy: 80.00%, Best Valid Accuracy: 82.35%, Test accuracy: 84.52%\n",
            "Epoch 93/110, Loss: 0.0310, Valid Accuracy: 83.53%, Best Valid Accuracy: 83.53%, Test accuracy: 84.52%\n",
            "Epoch 94/110, Loss: 0.0717, Valid Accuracy: 84.71%, Best Valid Accuracy: 84.71%, Test accuracy: 82.14%\n",
            "Epoch 95/110, Loss: 0.0107, Valid Accuracy: 78.82%, Best Valid Accuracy: 84.71%, Test accuracy: 80.95%\n",
            "Epoch 96/110, Loss: 0.0204, Valid Accuracy: 81.18%, Best Valid Accuracy: 84.71%, Test accuracy: 77.38%\n",
            "Epoch 97/110, Loss: 0.0213, Valid Accuracy: 78.82%, Best Valid Accuracy: 84.71%, Test accuracy: 79.76%\n",
            "Epoch 98/110, Loss: 0.0247, Valid Accuracy: 77.65%, Best Valid Accuracy: 84.71%, Test accuracy: 82.14%\n",
            "Epoch 99/110, Loss: 0.3726, Valid Accuracy: 78.82%, Best Valid Accuracy: 84.71%, Test accuracy: 82.14%\n",
            "Epoch 100/110, Loss: 0.1017, Valid Accuracy: 81.18%, Best Valid Accuracy: 84.71%, Test accuracy: 80.95%\n",
            "Epoch 101/110, Loss: 0.0221, Valid Accuracy: 78.82%, Best Valid Accuracy: 84.71%, Test accuracy: 79.76%\n",
            "Epoch 102/110, Loss: 0.0338, Valid Accuracy: 78.82%, Best Valid Accuracy: 84.71%, Test accuracy: 80.95%\n",
            "Epoch 103/110, Loss: 0.2860, Valid Accuracy: 80.00%, Best Valid Accuracy: 84.71%, Test accuracy: 82.14%\n",
            "Epoch 104/110, Loss: 0.0133, Valid Accuracy: 77.65%, Best Valid Accuracy: 84.71%, Test accuracy: 78.57%\n",
            "Epoch 105/110, Loss: 0.0010, Valid Accuracy: 77.65%, Best Valid Accuracy: 84.71%, Test accuracy: 80.95%\n",
            "Epoch 106/110, Loss: 0.1805, Valid Accuracy: 78.82%, Best Valid Accuracy: 84.71%, Test accuracy: 80.95%\n",
            "Epoch 107/110, Loss: 0.0470, Valid Accuracy: 78.82%, Best Valid Accuracy: 84.71%, Test accuracy: 80.95%\n",
            "Epoch 108/110, Loss: 0.0480, Valid Accuracy: 75.29%, Best Valid Accuracy: 84.71%, Test accuracy: 80.95%\n",
            "Epoch 109/110, Loss: 0.0901, Valid Accuracy: 77.65%, Best Valid Accuracy: 84.71%, Test accuracy: 82.14%\n",
            "Epoch 110/110, Loss: 0.0299, Valid Accuracy: 77.65%, Best Valid Accuracy: 84.71%, Test accuracy: 82.14%\n",
            "Training time: 25.56 seconds\n",
            "Total time: 26.71 seconds\n",
            "0.8214285714285714\n",
            "############### Config ###############\n",
            "{'accuracy_for_convergence': 0.6,\n",
            " 'add_time': True,\n",
            " 'attn_pdrop': 0.1,\n",
            " 'batch_size': 20,\n",
            " 'continue_training': False,\n",
            " 'dataset': 'TSC_SelfRegulationSCP1',\n",
            " 'downsampling': False,\n",
            " 'early_stop_ep': 500,\n",
            " 'embd_pdrop': 0.1,\n",
            " 'embedded_dim': 10,\n",
            " 'epoch': 110,\n",
            " 'epochs_for_convergence': 10000,\n",
            " 'eval_batch_size': -1,\n",
            " 'global_backward': True,\n",
            " 'global_forward': False,\n",
            " 'input_size': 5,\n",
            " 'irreg': True,\n",
            " 'local_tight': False,\n",
            " 'local_wide': False,\n",
            " 'local_width': 50,\n",
            " 'lr': 0.00040788,\n",
            " 'model': 'transformer',\n",
            " 'n_head': 3,\n",
            " 'n_seeds': 5,\n",
            " 'num_layers': 2,\n",
            " 'num_windows': 100,\n",
            " 'online_signature_calc': False,\n",
            " 'optimizer': 'Adam',\n",
            " 'overlap': False,\n",
            " 'pretrained_model_path': '',\n",
            " 'q_len': 1,\n",
            " 'random_percentage': 0.7,\n",
            " 'resid_pdrop': 0.1,\n",
            " 'save_all_epochs': False,\n",
            " 'scale_att': False,\n",
            " 'sig_level': 2,\n",
            " 'sig_win_len': 50,\n",
            " 'sparse': False,\n",
            " 'std_for_convergence': 0.05,\n",
            " 'sub_len': 1,\n",
            " 'test_size': 0.3,\n",
            " 'univariate': True,\n",
            " 'use_random_drop': False,\n",
            " 'use_signatures': True,\n",
            " 'v_partition': 0.1,\n",
            " 'val_size': 0.5,\n",
            " 'wandb': False,\n",
            " 'warmup_proportion': -1,\n",
            " 'weight_decay': 0,\n",
            " 'zero_shot_downsample': False}\n",
            "\n",
            "Seed: 44\n",
            "\n",
            "######################################\n",
            "Num features without signature:  6 Num features with signatures:  36\n",
            "Sequence length without signature:  896 Sequence length with signatures:  100\n",
            "\n",
            "Compression: 0.6696428571428571\n",
            "\n",
            "Compression L^2d: 0.07473692602040816\n",
            "\n",
            "Number of classes: 2\n",
            "---- Attn\n",
            "Query_Key_CNN: 12972\n",
            "Value_CNN: 6486\n",
            "C_proj_CNN: 6394\n",
            "--- Block\n",
            "attn: 25852\n",
            "mlp: 17158\n",
            "-- Transformer\n",
            "blocks: 86388\n",
            "po_embed: 1000\n",
            "-Decoder Transformer\n",
            "mlp: 94\n",
            "transformer: 87388\n",
            "Epoch 1/110, Loss: 0.6623, Valid Accuracy: 81.18%, Best Valid Accuracy: 81.18%, Test accuracy: 82.14%\n",
            "Epoch 2/110, Loss: 0.4921, Valid Accuracy: 77.65%, Best Valid Accuracy: 81.18%, Test accuracy: 80.95%\n",
            "Epoch 3/110, Loss: 0.4876, Valid Accuracy: 78.82%, Best Valid Accuracy: 81.18%, Test accuracy: 83.33%\n",
            "Epoch 4/110, Loss: 0.2987, Valid Accuracy: 78.82%, Best Valid Accuracy: 81.18%, Test accuracy: 82.14%\n",
            "Epoch 5/110, Loss: 0.3044, Valid Accuracy: 76.47%, Best Valid Accuracy: 81.18%, Test accuracy: 79.76%\n",
            "Epoch 6/110, Loss: 0.3140, Valid Accuracy: 78.82%, Best Valid Accuracy: 81.18%, Test accuracy: 80.95%\n",
            "Epoch 7/110, Loss: 0.2758, Valid Accuracy: 78.82%, Best Valid Accuracy: 81.18%, Test accuracy: 82.14%\n",
            "Epoch 8/110, Loss: 0.2759, Valid Accuracy: 78.82%, Best Valid Accuracy: 81.18%, Test accuracy: 84.52%\n",
            "Epoch 9/110, Loss: 0.1672, Valid Accuracy: 80.00%, Best Valid Accuracy: 81.18%, Test accuracy: 82.14%\n",
            "Epoch 10/110, Loss: 0.7138, Valid Accuracy: 81.18%, Best Valid Accuracy: 81.18%, Test accuracy: 83.33%\n",
            "Epoch 11/110, Loss: 0.2671, Valid Accuracy: 80.00%, Best Valid Accuracy: 81.18%, Test accuracy: 80.95%\n",
            "Epoch 12/110, Loss: 0.3916, Valid Accuracy: 82.35%, Best Valid Accuracy: 82.35%, Test accuracy: 84.52%\n",
            "Epoch 13/110, Loss: 0.5333, Valid Accuracy: 78.82%, Best Valid Accuracy: 82.35%, Test accuracy: 82.14%\n",
            "Epoch 14/110, Loss: 0.2109, Valid Accuracy: 84.71%, Best Valid Accuracy: 84.71%, Test accuracy: 83.33%\n",
            "Epoch 15/110, Loss: 0.2345, Valid Accuracy: 80.00%, Best Valid Accuracy: 84.71%, Test accuracy: 82.14%\n",
            "Epoch 16/110, Loss: 0.7358, Valid Accuracy: 84.71%, Best Valid Accuracy: 84.71%, Test accuracy: 85.71%\n",
            "Epoch 17/110, Loss: 0.6964, Valid Accuracy: 87.06%, Best Valid Accuracy: 87.06%, Test accuracy: 85.71%\n",
            "Epoch 18/110, Loss: 0.2733, Valid Accuracy: 84.71%, Best Valid Accuracy: 87.06%, Test accuracy: 85.71%\n",
            "Epoch 19/110, Loss: 0.2263, Valid Accuracy: 84.71%, Best Valid Accuracy: 87.06%, Test accuracy: 84.52%\n",
            "Epoch 20/110, Loss: 0.1756, Valid Accuracy: 81.18%, Best Valid Accuracy: 87.06%, Test accuracy: 85.71%\n",
            "Epoch 21/110, Loss: 0.3095, Valid Accuracy: 78.82%, Best Valid Accuracy: 87.06%, Test accuracy: 85.71%\n",
            "Epoch 22/110, Loss: 0.2539, Valid Accuracy: 87.06%, Best Valid Accuracy: 87.06%, Test accuracy: 88.10%\n",
            "Epoch 23/110, Loss: 0.1282, Valid Accuracy: 85.88%, Best Valid Accuracy: 87.06%, Test accuracy: 88.10%\n",
            "Epoch 24/110, Loss: 0.4135, Valid Accuracy: 83.53%, Best Valid Accuracy: 87.06%, Test accuracy: 85.71%\n",
            "Epoch 25/110, Loss: 0.0330, Valid Accuracy: 81.18%, Best Valid Accuracy: 87.06%, Test accuracy: 82.14%\n",
            "Epoch 26/110, Loss: 0.2301, Valid Accuracy: 81.18%, Best Valid Accuracy: 87.06%, Test accuracy: 83.33%\n",
            "Epoch 27/110, Loss: 0.2963, Valid Accuracy: 80.00%, Best Valid Accuracy: 87.06%, Test accuracy: 86.90%\n",
            "Epoch 28/110, Loss: 0.1408, Valid Accuracy: 78.82%, Best Valid Accuracy: 87.06%, Test accuracy: 88.10%\n",
            "Epoch 29/110, Loss: 0.0563, Valid Accuracy: 85.88%, Best Valid Accuracy: 87.06%, Test accuracy: 84.52%\n",
            "Epoch 30/110, Loss: 0.0607, Valid Accuracy: 81.18%, Best Valid Accuracy: 87.06%, Test accuracy: 86.90%\n",
            "Epoch 31/110, Loss: 0.0463, Valid Accuracy: 83.53%, Best Valid Accuracy: 87.06%, Test accuracy: 88.10%\n",
            "Epoch 32/110, Loss: 0.1278, Valid Accuracy: 83.53%, Best Valid Accuracy: 87.06%, Test accuracy: 88.10%\n",
            "Epoch 33/110, Loss: 0.1205, Valid Accuracy: 87.06%, Best Valid Accuracy: 87.06%, Test accuracy: 86.90%\n",
            "Epoch 34/110, Loss: 0.0428, Valid Accuracy: 82.35%, Best Valid Accuracy: 87.06%, Test accuracy: 88.10%\n",
            "Epoch 35/110, Loss: 0.1455, Valid Accuracy: 81.18%, Best Valid Accuracy: 87.06%, Test accuracy: 86.90%\n",
            "Epoch 36/110, Loss: 0.1123, Valid Accuracy: 83.53%, Best Valid Accuracy: 87.06%, Test accuracy: 85.71%\n",
            "Epoch 37/110, Loss: 0.0829, Valid Accuracy: 80.00%, Best Valid Accuracy: 87.06%, Test accuracy: 86.90%\n",
            "Epoch 38/110, Loss: 0.2488, Valid Accuracy: 83.53%, Best Valid Accuracy: 87.06%, Test accuracy: 88.10%\n",
            "Epoch 39/110, Loss: 0.0809, Valid Accuracy: 78.82%, Best Valid Accuracy: 87.06%, Test accuracy: 90.48%\n",
            "Epoch 40/110, Loss: 0.2666, Valid Accuracy: 82.35%, Best Valid Accuracy: 87.06%, Test accuracy: 85.71%\n",
            "Epoch 41/110, Loss: 0.1610, Valid Accuracy: 81.18%, Best Valid Accuracy: 87.06%, Test accuracy: 85.71%\n",
            "Epoch 42/110, Loss: 0.0907, Valid Accuracy: 85.88%, Best Valid Accuracy: 87.06%, Test accuracy: 86.90%\n",
            "Epoch 43/110, Loss: 0.3242, Valid Accuracy: 80.00%, Best Valid Accuracy: 87.06%, Test accuracy: 84.52%\n",
            "Epoch 44/110, Loss: 0.3658, Valid Accuracy: 87.06%, Best Valid Accuracy: 87.06%, Test accuracy: 84.52%\n",
            "Epoch 45/110, Loss: 0.1885, Valid Accuracy: 88.24%, Best Valid Accuracy: 88.24%, Test accuracy: 86.90%\n",
            "Epoch 46/110, Loss: 0.2458, Valid Accuracy: 90.59%, Best Valid Accuracy: 90.59%, Test accuracy: 86.90%\n",
            "Epoch 47/110, Loss: 0.6089, Valid Accuracy: 88.24%, Best Valid Accuracy: 90.59%, Test accuracy: 84.52%\n",
            "Epoch 48/110, Loss: 0.0994, Valid Accuracy: 85.88%, Best Valid Accuracy: 90.59%, Test accuracy: 83.33%\n",
            "Epoch 49/110, Loss: 0.1156, Valid Accuracy: 83.53%, Best Valid Accuracy: 90.59%, Test accuracy: 82.14%\n",
            "Epoch 50/110, Loss: 0.2464, Valid Accuracy: 78.82%, Best Valid Accuracy: 90.59%, Test accuracy: 83.33%\n",
            "Epoch 51/110, Loss: 0.1118, Valid Accuracy: 82.35%, Best Valid Accuracy: 90.59%, Test accuracy: 84.52%\n",
            "Epoch 52/110, Loss: 0.1848, Valid Accuracy: 87.06%, Best Valid Accuracy: 90.59%, Test accuracy: 85.71%\n",
            "Epoch 53/110, Loss: 0.0760, Valid Accuracy: 80.00%, Best Valid Accuracy: 90.59%, Test accuracy: 86.90%\n",
            "Epoch 54/110, Loss: 0.0666, Valid Accuracy: 78.82%, Best Valid Accuracy: 90.59%, Test accuracy: 79.76%\n",
            "Epoch 55/110, Loss: 0.0058, Valid Accuracy: 78.82%, Best Valid Accuracy: 90.59%, Test accuracy: 82.14%\n",
            "Epoch 56/110, Loss: 0.0264, Valid Accuracy: 78.82%, Best Valid Accuracy: 90.59%, Test accuracy: 82.14%\n",
            "Epoch 57/110, Loss: 0.7092, Valid Accuracy: 75.29%, Best Valid Accuracy: 90.59%, Test accuracy: 82.14%\n",
            "Epoch 58/110, Loss: 0.1544, Valid Accuracy: 76.47%, Best Valid Accuracy: 90.59%, Test accuracy: 76.19%\n",
            "Epoch 59/110, Loss: 0.1668, Valid Accuracy: 76.47%, Best Valid Accuracy: 90.59%, Test accuracy: 80.95%\n",
            "Epoch 60/110, Loss: 0.2997, Valid Accuracy: 77.65%, Best Valid Accuracy: 90.59%, Test accuracy: 79.76%\n",
            "Epoch 61/110, Loss: 0.3955, Valid Accuracy: 76.47%, Best Valid Accuracy: 90.59%, Test accuracy: 78.57%\n",
            "Epoch 62/110, Loss: 0.4086, Valid Accuracy: 76.47%, Best Valid Accuracy: 90.59%, Test accuracy: 79.76%\n",
            "Epoch 63/110, Loss: 0.8053, Valid Accuracy: 78.82%, Best Valid Accuracy: 90.59%, Test accuracy: 88.10%\n",
            "Epoch 64/110, Loss: 0.0366, Valid Accuracy: 82.35%, Best Valid Accuracy: 90.59%, Test accuracy: 86.90%\n",
            "Epoch 65/110, Loss: 0.0974, Valid Accuracy: 82.35%, Best Valid Accuracy: 90.59%, Test accuracy: 78.57%\n",
            "Epoch 66/110, Loss: 0.2128, Valid Accuracy: 77.65%, Best Valid Accuracy: 90.59%, Test accuracy: 82.14%\n",
            "Epoch 67/110, Loss: 0.0259, Valid Accuracy: 72.94%, Best Valid Accuracy: 90.59%, Test accuracy: 80.95%\n",
            "Epoch 68/110, Loss: 0.1436, Valid Accuracy: 75.29%, Best Valid Accuracy: 90.59%, Test accuracy: 82.14%\n",
            "Epoch 69/110, Loss: 0.3732, Valid Accuracy: 75.29%, Best Valid Accuracy: 90.59%, Test accuracy: 80.95%\n",
            "Epoch 70/110, Loss: 0.0643, Valid Accuracy: 80.00%, Best Valid Accuracy: 90.59%, Test accuracy: 82.14%\n",
            "Epoch 71/110, Loss: 0.1184, Valid Accuracy: 78.82%, Best Valid Accuracy: 90.59%, Test accuracy: 78.57%\n",
            "Epoch 72/110, Loss: 0.3040, Valid Accuracy: 82.35%, Best Valid Accuracy: 90.59%, Test accuracy: 79.76%\n",
            "Epoch 73/110, Loss: 0.1012, Valid Accuracy: 82.35%, Best Valid Accuracy: 90.59%, Test accuracy: 77.38%\n",
            "Epoch 74/110, Loss: 0.0196, Valid Accuracy: 85.88%, Best Valid Accuracy: 90.59%, Test accuracy: 79.76%\n",
            "Epoch 75/110, Loss: 0.5898, Valid Accuracy: 85.88%, Best Valid Accuracy: 90.59%, Test accuracy: 80.95%\n",
            "Epoch 76/110, Loss: 0.0460, Valid Accuracy: 83.53%, Best Valid Accuracy: 90.59%, Test accuracy: 80.95%\n",
            "Epoch 77/110, Loss: 0.0546, Valid Accuracy: 84.71%, Best Valid Accuracy: 90.59%, Test accuracy: 82.14%\n",
            "Epoch 78/110, Loss: 0.0597, Valid Accuracy: 83.53%, Best Valid Accuracy: 90.59%, Test accuracy: 82.14%\n",
            "Epoch 79/110, Loss: 0.2743, Valid Accuracy: 82.35%, Best Valid Accuracy: 90.59%, Test accuracy: 79.76%\n",
            "Epoch 80/110, Loss: 0.0384, Valid Accuracy: 82.35%, Best Valid Accuracy: 90.59%, Test accuracy: 82.14%\n",
            "Epoch 81/110, Loss: 0.0242, Valid Accuracy: 82.35%, Best Valid Accuracy: 90.59%, Test accuracy: 78.57%\n",
            "Epoch 82/110, Loss: 0.0748, Valid Accuracy: 81.18%, Best Valid Accuracy: 90.59%, Test accuracy: 76.19%\n",
            "Epoch 83/110, Loss: 0.0128, Valid Accuracy: 82.35%, Best Valid Accuracy: 90.59%, Test accuracy: 79.76%\n",
            "Epoch 84/110, Loss: 0.0298, Valid Accuracy: 82.35%, Best Valid Accuracy: 90.59%, Test accuracy: 84.52%\n",
            "Epoch 85/110, Loss: 0.0164, Valid Accuracy: 80.00%, Best Valid Accuracy: 90.59%, Test accuracy: 84.52%\n",
            "Epoch 86/110, Loss: 0.1008, Valid Accuracy: 80.00%, Best Valid Accuracy: 90.59%, Test accuracy: 86.90%\n",
            "Epoch 87/110, Loss: 0.0849, Valid Accuracy: 78.82%, Best Valid Accuracy: 90.59%, Test accuracy: 80.95%\n",
            "Epoch 88/110, Loss: 0.0601, Valid Accuracy: 80.00%, Best Valid Accuracy: 90.59%, Test accuracy: 84.52%\n",
            "Epoch 89/110, Loss: 0.0502, Valid Accuracy: 80.00%, Best Valid Accuracy: 90.59%, Test accuracy: 83.33%\n",
            "Epoch 90/110, Loss: 0.2821, Valid Accuracy: 84.71%, Best Valid Accuracy: 90.59%, Test accuracy: 84.52%\n",
            "Epoch 91/110, Loss: 0.4919, Valid Accuracy: 85.88%, Best Valid Accuracy: 90.59%, Test accuracy: 84.52%\n",
            "Epoch 92/110, Loss: 0.5876, Valid Accuracy: 81.18%, Best Valid Accuracy: 90.59%, Test accuracy: 84.52%\n",
            "Epoch 93/110, Loss: 0.1725, Valid Accuracy: 77.65%, Best Valid Accuracy: 90.59%, Test accuracy: 88.10%\n",
            "Epoch 94/110, Loss: 0.1651, Valid Accuracy: 83.53%, Best Valid Accuracy: 90.59%, Test accuracy: 85.71%\n",
            "Epoch 95/110, Loss: 0.0110, Valid Accuracy: 84.71%, Best Valid Accuracy: 90.59%, Test accuracy: 83.33%\n",
            "Epoch 96/110, Loss: 0.0168, Valid Accuracy: 85.88%, Best Valid Accuracy: 90.59%, Test accuracy: 84.52%\n",
            "Epoch 97/110, Loss: 0.0286, Valid Accuracy: 83.53%, Best Valid Accuracy: 90.59%, Test accuracy: 84.52%\n",
            "Epoch 98/110, Loss: 0.0211, Valid Accuracy: 82.35%, Best Valid Accuracy: 90.59%, Test accuracy: 82.14%\n",
            "Epoch 99/110, Loss: 0.0125, Valid Accuracy: 82.35%, Best Valid Accuracy: 90.59%, Test accuracy: 82.14%\n",
            "Epoch 100/110, Loss: 0.0012, Valid Accuracy: 82.35%, Best Valid Accuracy: 90.59%, Test accuracy: 85.71%\n",
            "Epoch 101/110, Loss: 0.0768, Valid Accuracy: 84.71%, Best Valid Accuracy: 90.59%, Test accuracy: 85.71%\n",
            "Epoch 102/110, Loss: 0.0282, Valid Accuracy: 82.35%, Best Valid Accuracy: 90.59%, Test accuracy: 80.95%\n",
            "Epoch 103/110, Loss: 0.1477, Valid Accuracy: 82.35%, Best Valid Accuracy: 90.59%, Test accuracy: 79.76%\n",
            "Epoch 104/110, Loss: 0.0753, Valid Accuracy: 82.35%, Best Valid Accuracy: 90.59%, Test accuracy: 82.14%\n",
            "Epoch 105/110, Loss: 0.0139, Valid Accuracy: 80.00%, Best Valid Accuracy: 90.59%, Test accuracy: 84.52%\n",
            "Epoch 106/110, Loss: 0.2510, Valid Accuracy: 80.00%, Best Valid Accuracy: 90.59%, Test accuracy: 84.52%\n",
            "Epoch 107/110, Loss: 0.1038, Valid Accuracy: 78.82%, Best Valid Accuracy: 90.59%, Test accuracy: 84.52%\n",
            "Epoch 108/110, Loss: 0.1934, Valid Accuracy: 85.88%, Best Valid Accuracy: 90.59%, Test accuracy: 86.90%\n",
            "Epoch 109/110, Loss: 0.0260, Valid Accuracy: 87.06%, Best Valid Accuracy: 90.59%, Test accuracy: 84.52%\n",
            "Epoch 110/110, Loss: 0.0119, Valid Accuracy: 83.53%, Best Valid Accuracy: 90.59%, Test accuracy: 86.90%\n",
            "Training time: 25.75 seconds\n",
            "Total time: 27.42 seconds\n",
            "0.8690476190476191\n",
            "############### Config ###############\n",
            "{'accuracy_for_convergence': 0.6,\n",
            " 'add_time': True,\n",
            " 'attn_pdrop': 0.1,\n",
            " 'batch_size': 20,\n",
            " 'continue_training': False,\n",
            " 'dataset': 'TSC_SelfRegulationSCP1',\n",
            " 'downsampling': False,\n",
            " 'early_stop_ep': 500,\n",
            " 'embd_pdrop': 0.1,\n",
            " 'embedded_dim': 10,\n",
            " 'epoch': 110,\n",
            " 'epochs_for_convergence': 10000,\n",
            " 'eval_batch_size': -1,\n",
            " 'global_backward': True,\n",
            " 'global_forward': False,\n",
            " 'input_size': 5,\n",
            " 'irreg': True,\n",
            " 'local_tight': False,\n",
            " 'local_wide': False,\n",
            " 'local_width': 50,\n",
            " 'lr': 0.00040788,\n",
            " 'model': 'transformer',\n",
            " 'n_head': 3,\n",
            " 'n_seeds': 5,\n",
            " 'num_layers': 2,\n",
            " 'num_windows': 100,\n",
            " 'online_signature_calc': False,\n",
            " 'optimizer': 'Adam',\n",
            " 'overlap': False,\n",
            " 'pretrained_model_path': '',\n",
            " 'q_len': 1,\n",
            " 'random_percentage': 0.7,\n",
            " 'resid_pdrop': 0.1,\n",
            " 'save_all_epochs': False,\n",
            " 'scale_att': False,\n",
            " 'sig_level': 2,\n",
            " 'sig_win_len': 50,\n",
            " 'sparse': False,\n",
            " 'std_for_convergence': 0.05,\n",
            " 'sub_len': 1,\n",
            " 'test_size': 0.3,\n",
            " 'univariate': True,\n",
            " 'use_random_drop': False,\n",
            " 'use_signatures': True,\n",
            " 'v_partition': 0.1,\n",
            " 'val_size': 0.5,\n",
            " 'wandb': False,\n",
            " 'warmup_proportion': -1,\n",
            " 'weight_decay': 0,\n",
            " 'zero_shot_downsample': False}\n",
            "\n",
            "Seed: 45\n",
            "\n",
            "######################################\n",
            "Num features without signature:  6 Num features with signatures:  36\n",
            "Sequence length without signature:  896 Sequence length with signatures:  100\n",
            "\n",
            "Compression: 0.6696428571428571\n",
            "\n",
            "Compression L^2d: 0.07473692602040816\n",
            "\n",
            "Number of classes: 2\n",
            "---- Attn\n",
            "Query_Key_CNN: 12972\n",
            "Value_CNN: 6486\n",
            "C_proj_CNN: 6394\n",
            "--- Block\n",
            "attn: 25852\n",
            "mlp: 17158\n",
            "-- Transformer\n",
            "blocks: 86388\n",
            "po_embed: 1000\n",
            "-Decoder Transformer\n",
            "mlp: 94\n",
            "transformer: 87388\n",
            "Epoch 1/110, Loss: 0.6399, Valid Accuracy: 83.53%, Best Valid Accuracy: 83.53%, Test accuracy: 86.90%\n",
            "Epoch 2/110, Loss: 0.5511, Valid Accuracy: 92.94%, Best Valid Accuracy: 92.94%, Test accuracy: 82.14%\n",
            "Epoch 3/110, Loss: 0.5417, Valid Accuracy: 90.59%, Best Valid Accuracy: 92.94%, Test accuracy: 79.76%\n",
            "Epoch 4/110, Loss: 0.4551, Valid Accuracy: 87.06%, Best Valid Accuracy: 92.94%, Test accuracy: 80.95%\n",
            "Epoch 5/110, Loss: 0.5614, Valid Accuracy: 87.06%, Best Valid Accuracy: 92.94%, Test accuracy: 85.71%\n",
            "Epoch 6/110, Loss: 0.3496, Valid Accuracy: 87.06%, Best Valid Accuracy: 92.94%, Test accuracy: 84.52%\n",
            "Epoch 7/110, Loss: 0.2409, Valid Accuracy: 85.88%, Best Valid Accuracy: 92.94%, Test accuracy: 85.71%\n",
            "Epoch 8/110, Loss: 0.5210, Valid Accuracy: 91.76%, Best Valid Accuracy: 92.94%, Test accuracy: 78.57%\n",
            "Epoch 9/110, Loss: 0.4387, Valid Accuracy: 90.59%, Best Valid Accuracy: 92.94%, Test accuracy: 80.95%\n",
            "Epoch 10/110, Loss: 0.5840, Valid Accuracy: 84.71%, Best Valid Accuracy: 92.94%, Test accuracy: 83.33%\n",
            "Epoch 11/110, Loss: 0.3715, Valid Accuracy: 85.88%, Best Valid Accuracy: 92.94%, Test accuracy: 84.52%\n",
            "Epoch 12/110, Loss: 0.1394, Valid Accuracy: 87.06%, Best Valid Accuracy: 92.94%, Test accuracy: 84.52%\n",
            "Epoch 13/110, Loss: 0.2506, Valid Accuracy: 88.24%, Best Valid Accuracy: 92.94%, Test accuracy: 84.52%\n",
            "Epoch 14/110, Loss: 0.3253, Valid Accuracy: 84.71%, Best Valid Accuracy: 92.94%, Test accuracy: 82.14%\n",
            "Epoch 15/110, Loss: 0.1646, Valid Accuracy: 85.88%, Best Valid Accuracy: 92.94%, Test accuracy: 86.90%\n",
            "Epoch 16/110, Loss: 0.2736, Valid Accuracy: 87.06%, Best Valid Accuracy: 92.94%, Test accuracy: 85.71%\n",
            "Epoch 17/110, Loss: 0.0473, Valid Accuracy: 89.41%, Best Valid Accuracy: 92.94%, Test accuracy: 84.52%\n",
            "Epoch 18/110, Loss: 0.6749, Valid Accuracy: 87.06%, Best Valid Accuracy: 92.94%, Test accuracy: 84.52%\n",
            "Epoch 19/110, Loss: 0.4323, Valid Accuracy: 89.41%, Best Valid Accuracy: 92.94%, Test accuracy: 85.71%\n",
            "Epoch 20/110, Loss: 0.4267, Valid Accuracy: 85.88%, Best Valid Accuracy: 92.94%, Test accuracy: 84.52%\n",
            "Epoch 21/110, Loss: 0.1665, Valid Accuracy: 85.88%, Best Valid Accuracy: 92.94%, Test accuracy: 83.33%\n",
            "Epoch 22/110, Loss: 0.3673, Valid Accuracy: 85.88%, Best Valid Accuracy: 92.94%, Test accuracy: 84.52%\n",
            "Epoch 23/110, Loss: 0.0967, Valid Accuracy: 83.53%, Best Valid Accuracy: 92.94%, Test accuracy: 85.71%\n",
            "Epoch 24/110, Loss: 0.5161, Valid Accuracy: 85.88%, Best Valid Accuracy: 92.94%, Test accuracy: 83.33%\n",
            "Epoch 25/110, Loss: 0.2013, Valid Accuracy: 90.59%, Best Valid Accuracy: 92.94%, Test accuracy: 84.52%\n",
            "Epoch 26/110, Loss: 0.1270, Valid Accuracy: 88.24%, Best Valid Accuracy: 92.94%, Test accuracy: 83.33%\n",
            "Epoch 27/110, Loss: 0.4960, Valid Accuracy: 84.71%, Best Valid Accuracy: 92.94%, Test accuracy: 82.14%\n",
            "Epoch 28/110, Loss: 0.4576, Valid Accuracy: 87.06%, Best Valid Accuracy: 92.94%, Test accuracy: 82.14%\n",
            "Epoch 29/110, Loss: 0.2743, Valid Accuracy: 84.71%, Best Valid Accuracy: 92.94%, Test accuracy: 82.14%\n",
            "Epoch 30/110, Loss: 0.1599, Valid Accuracy: 83.53%, Best Valid Accuracy: 92.94%, Test accuracy: 80.95%\n",
            "Epoch 31/110, Loss: 0.3697, Valid Accuracy: 85.88%, Best Valid Accuracy: 92.94%, Test accuracy: 83.33%\n",
            "Epoch 32/110, Loss: 0.1410, Valid Accuracy: 85.88%, Best Valid Accuracy: 92.94%, Test accuracy: 85.71%\n",
            "Epoch 33/110, Loss: 0.1827, Valid Accuracy: 87.06%, Best Valid Accuracy: 92.94%, Test accuracy: 86.90%\n",
            "Epoch 34/110, Loss: 0.4207, Valid Accuracy: 87.06%, Best Valid Accuracy: 92.94%, Test accuracy: 82.14%\n",
            "Epoch 35/110, Loss: 0.1716, Valid Accuracy: 85.88%, Best Valid Accuracy: 92.94%, Test accuracy: 85.71%\n",
            "Epoch 36/110, Loss: 0.1620, Valid Accuracy: 83.53%, Best Valid Accuracy: 92.94%, Test accuracy: 84.52%\n",
            "Epoch 37/110, Loss: 0.2104, Valid Accuracy: 88.24%, Best Valid Accuracy: 92.94%, Test accuracy: 84.52%\n",
            "Epoch 38/110, Loss: 0.1460, Valid Accuracy: 84.71%, Best Valid Accuracy: 92.94%, Test accuracy: 86.90%\n",
            "Epoch 39/110, Loss: 0.2677, Valid Accuracy: 83.53%, Best Valid Accuracy: 92.94%, Test accuracy: 88.10%\n",
            "Epoch 40/110, Loss: 0.3963, Valid Accuracy: 81.18%, Best Valid Accuracy: 92.94%, Test accuracy: 84.52%\n",
            "Epoch 41/110, Loss: 0.2903, Valid Accuracy: 89.41%, Best Valid Accuracy: 92.94%, Test accuracy: 79.76%\n",
            "Epoch 42/110, Loss: 0.3422, Valid Accuracy: 88.24%, Best Valid Accuracy: 92.94%, Test accuracy: 84.52%\n",
            "Epoch 43/110, Loss: 0.0355, Valid Accuracy: 84.71%, Best Valid Accuracy: 92.94%, Test accuracy: 84.52%\n",
            "Epoch 44/110, Loss: 0.2054, Valid Accuracy: 88.24%, Best Valid Accuracy: 92.94%, Test accuracy: 83.33%\n",
            "Epoch 45/110, Loss: 0.4524, Valid Accuracy: 83.53%, Best Valid Accuracy: 92.94%, Test accuracy: 78.57%\n",
            "Epoch 46/110, Loss: 0.2284, Valid Accuracy: 87.06%, Best Valid Accuracy: 92.94%, Test accuracy: 83.33%\n",
            "Epoch 47/110, Loss: 0.3942, Valid Accuracy: 88.24%, Best Valid Accuracy: 92.94%, Test accuracy: 82.14%\n",
            "Epoch 48/110, Loss: 0.3143, Valid Accuracy: 85.88%, Best Valid Accuracy: 92.94%, Test accuracy: 83.33%\n",
            "Epoch 49/110, Loss: 0.0854, Valid Accuracy: 83.53%, Best Valid Accuracy: 92.94%, Test accuracy: 83.33%\n",
            "Epoch 50/110, Loss: 0.1376, Valid Accuracy: 84.71%, Best Valid Accuracy: 92.94%, Test accuracy: 84.52%\n",
            "Epoch 51/110, Loss: 0.1750, Valid Accuracy: 87.06%, Best Valid Accuracy: 92.94%, Test accuracy: 80.95%\n",
            "Epoch 52/110, Loss: 0.0532, Valid Accuracy: 82.35%, Best Valid Accuracy: 92.94%, Test accuracy: 79.76%\n",
            "Epoch 53/110, Loss: 0.2600, Valid Accuracy: 85.88%, Best Valid Accuracy: 92.94%, Test accuracy: 83.33%\n",
            "Epoch 54/110, Loss: 0.0456, Valid Accuracy: 84.71%, Best Valid Accuracy: 92.94%, Test accuracy: 80.95%\n",
            "Epoch 55/110, Loss: 0.0596, Valid Accuracy: 89.41%, Best Valid Accuracy: 92.94%, Test accuracy: 84.52%\n",
            "Epoch 56/110, Loss: 0.0609, Valid Accuracy: 89.41%, Best Valid Accuracy: 92.94%, Test accuracy: 82.14%\n",
            "Epoch 57/110, Loss: 0.0602, Valid Accuracy: 87.06%, Best Valid Accuracy: 92.94%, Test accuracy: 82.14%\n",
            "Epoch 58/110, Loss: 0.1949, Valid Accuracy: 84.71%, Best Valid Accuracy: 92.94%, Test accuracy: 86.90%\n",
            "Epoch 59/110, Loss: 0.0848, Valid Accuracy: 88.24%, Best Valid Accuracy: 92.94%, Test accuracy: 80.95%\n",
            "Epoch 60/110, Loss: 0.0207, Valid Accuracy: 90.59%, Best Valid Accuracy: 92.94%, Test accuracy: 79.76%\n",
            "Epoch 61/110, Loss: 0.0811, Valid Accuracy: 87.06%, Best Valid Accuracy: 92.94%, Test accuracy: 80.95%\n",
            "Epoch 62/110, Loss: 0.0085, Valid Accuracy: 88.24%, Best Valid Accuracy: 92.94%, Test accuracy: 78.57%\n",
            "Epoch 63/110, Loss: 0.0724, Valid Accuracy: 87.06%, Best Valid Accuracy: 92.94%, Test accuracy: 78.57%\n",
            "Epoch 64/110, Loss: 0.1639, Valid Accuracy: 89.41%, Best Valid Accuracy: 92.94%, Test accuracy: 82.14%\n",
            "Epoch 65/110, Loss: 0.0506, Valid Accuracy: 90.59%, Best Valid Accuracy: 92.94%, Test accuracy: 80.95%\n",
            "Epoch 66/110, Loss: 0.0224, Valid Accuracy: 90.59%, Best Valid Accuracy: 92.94%, Test accuracy: 80.95%\n",
            "Epoch 67/110, Loss: 0.0683, Valid Accuracy: 87.06%, Best Valid Accuracy: 92.94%, Test accuracy: 80.95%\n",
            "Epoch 68/110, Loss: 0.0213, Valid Accuracy: 89.41%, Best Valid Accuracy: 92.94%, Test accuracy: 84.52%\n",
            "Epoch 69/110, Loss: 0.2286, Valid Accuracy: 88.24%, Best Valid Accuracy: 92.94%, Test accuracy: 84.52%\n",
            "Epoch 70/110, Loss: 0.0592, Valid Accuracy: 85.88%, Best Valid Accuracy: 92.94%, Test accuracy: 82.14%\n",
            "Epoch 71/110, Loss: 0.0850, Valid Accuracy: 90.59%, Best Valid Accuracy: 92.94%, Test accuracy: 85.71%\n",
            "Epoch 72/110, Loss: 0.0052, Valid Accuracy: 91.76%, Best Valid Accuracy: 92.94%, Test accuracy: 80.95%\n",
            "Epoch 73/110, Loss: 0.1620, Valid Accuracy: 83.53%, Best Valid Accuracy: 92.94%, Test accuracy: 82.14%\n",
            "Epoch 74/110, Loss: 0.0788, Valid Accuracy: 84.71%, Best Valid Accuracy: 92.94%, Test accuracy: 83.33%\n",
            "Epoch 75/110, Loss: 0.0169, Valid Accuracy: 85.88%, Best Valid Accuracy: 92.94%, Test accuracy: 85.71%\n",
            "Epoch 76/110, Loss: 0.0401, Valid Accuracy: 82.35%, Best Valid Accuracy: 92.94%, Test accuracy: 80.95%\n",
            "Epoch 77/110, Loss: 0.1300, Valid Accuracy: 85.88%, Best Valid Accuracy: 92.94%, Test accuracy: 83.33%\n",
            "Epoch 78/110, Loss: 0.0117, Valid Accuracy: 85.88%, Best Valid Accuracy: 92.94%, Test accuracy: 80.95%\n",
            "Epoch 79/110, Loss: 0.1188, Valid Accuracy: 84.71%, Best Valid Accuracy: 92.94%, Test accuracy: 82.14%\n",
            "Epoch 80/110, Loss: 0.0090, Valid Accuracy: 77.65%, Best Valid Accuracy: 92.94%, Test accuracy: 73.81%\n",
            "Epoch 81/110, Loss: 0.0126, Valid Accuracy: 82.35%, Best Valid Accuracy: 92.94%, Test accuracy: 79.76%\n",
            "Epoch 82/110, Loss: 0.1688, Valid Accuracy: 87.06%, Best Valid Accuracy: 92.94%, Test accuracy: 85.71%\n",
            "Epoch 83/110, Loss: 0.0947, Valid Accuracy: 85.88%, Best Valid Accuracy: 92.94%, Test accuracy: 75.00%\n",
            "Epoch 84/110, Loss: 0.0597, Valid Accuracy: 88.24%, Best Valid Accuracy: 92.94%, Test accuracy: 82.14%\n",
            "Epoch 85/110, Loss: 0.0365, Valid Accuracy: 84.71%, Best Valid Accuracy: 92.94%, Test accuracy: 82.14%\n",
            "Epoch 86/110, Loss: 0.0353, Valid Accuracy: 85.88%, Best Valid Accuracy: 92.94%, Test accuracy: 85.71%\n",
            "Epoch 87/110, Loss: 0.2935, Valid Accuracy: 85.88%, Best Valid Accuracy: 92.94%, Test accuracy: 82.14%\n",
            "Epoch 88/110, Loss: 0.0149, Valid Accuracy: 84.71%, Best Valid Accuracy: 92.94%, Test accuracy: 84.52%\n",
            "Epoch 89/110, Loss: 0.1132, Valid Accuracy: 82.35%, Best Valid Accuracy: 92.94%, Test accuracy: 80.95%\n",
            "Epoch 90/110, Loss: 0.0096, Valid Accuracy: 84.71%, Best Valid Accuracy: 92.94%, Test accuracy: 83.33%\n",
            "Epoch 91/110, Loss: 0.0409, Valid Accuracy: 85.88%, Best Valid Accuracy: 92.94%, Test accuracy: 82.14%\n",
            "Epoch 92/110, Loss: 0.0365, Valid Accuracy: 87.06%, Best Valid Accuracy: 92.94%, Test accuracy: 85.71%\n",
            "Epoch 93/110, Loss: 0.0068, Valid Accuracy: 84.71%, Best Valid Accuracy: 92.94%, Test accuracy: 85.71%\n",
            "Epoch 94/110, Loss: 0.0106, Valid Accuracy: 85.88%, Best Valid Accuracy: 92.94%, Test accuracy: 82.14%\n",
            "Epoch 95/110, Loss: 0.0362, Valid Accuracy: 85.88%, Best Valid Accuracy: 92.94%, Test accuracy: 83.33%\n",
            "Epoch 96/110, Loss: 0.0374, Valid Accuracy: 85.88%, Best Valid Accuracy: 92.94%, Test accuracy: 88.10%\n",
            "Epoch 97/110, Loss: 0.3150, Valid Accuracy: 83.53%, Best Valid Accuracy: 92.94%, Test accuracy: 78.57%\n",
            "Epoch 98/110, Loss: 0.1116, Valid Accuracy: 90.59%, Best Valid Accuracy: 92.94%, Test accuracy: 85.71%\n",
            "Epoch 99/110, Loss: 0.0862, Valid Accuracy: 88.24%, Best Valid Accuracy: 92.94%, Test accuracy: 84.52%\n",
            "Epoch 100/110, Loss: 0.0206, Valid Accuracy: 84.71%, Best Valid Accuracy: 92.94%, Test accuracy: 82.14%\n",
            "Epoch 101/110, Loss: 0.0233, Valid Accuracy: 87.06%, Best Valid Accuracy: 92.94%, Test accuracy: 85.71%\n",
            "Epoch 102/110, Loss: 0.0060, Valid Accuracy: 90.59%, Best Valid Accuracy: 92.94%, Test accuracy: 85.71%\n",
            "Epoch 103/110, Loss: 0.0021, Valid Accuracy: 88.24%, Best Valid Accuracy: 92.94%, Test accuracy: 86.90%\n",
            "Epoch 104/110, Loss: 0.0542, Valid Accuracy: 90.59%, Best Valid Accuracy: 92.94%, Test accuracy: 85.71%\n",
            "Epoch 105/110, Loss: 0.0163, Valid Accuracy: 88.24%, Best Valid Accuracy: 92.94%, Test accuracy: 83.33%\n",
            "Epoch 106/110, Loss: 0.0204, Valid Accuracy: 83.53%, Best Valid Accuracy: 92.94%, Test accuracy: 88.10%\n",
            "Epoch 107/110, Loss: 0.0033, Valid Accuracy: 88.24%, Best Valid Accuracy: 92.94%, Test accuracy: 83.33%\n",
            "Epoch 108/110, Loss: 0.0252, Valid Accuracy: 89.41%, Best Valid Accuracy: 92.94%, Test accuracy: 85.71%\n",
            "Epoch 109/110, Loss: 0.0056, Valid Accuracy: 85.88%, Best Valid Accuracy: 92.94%, Test accuracy: 84.52%\n",
            "Epoch 110/110, Loss: 0.0239, Valid Accuracy: 89.41%, Best Valid Accuracy: 92.94%, Test accuracy: 82.14%\n",
            "Training time: 25.68 seconds\n",
            "Total time: 27.45 seconds\n",
            "0.8214285714285714\n",
            "############### Config ###############\n",
            "{'accuracy_for_convergence': 0.6,\n",
            " 'add_time': True,\n",
            " 'attn_pdrop': 0.1,\n",
            " 'batch_size': 20,\n",
            " 'continue_training': False,\n",
            " 'dataset': 'TSC_SelfRegulationSCP1',\n",
            " 'downsampling': False,\n",
            " 'early_stop_ep': 500,\n",
            " 'embd_pdrop': 0.1,\n",
            " 'embedded_dim': 10,\n",
            " 'epoch': 110,\n",
            " 'epochs_for_convergence': 10000,\n",
            " 'eval_batch_size': -1,\n",
            " 'global_backward': True,\n",
            " 'global_forward': False,\n",
            " 'input_size': 5,\n",
            " 'irreg': True,\n",
            " 'local_tight': False,\n",
            " 'local_wide': False,\n",
            " 'local_width': 50,\n",
            " 'lr': 0.00040788,\n",
            " 'model': 'transformer',\n",
            " 'n_head': 3,\n",
            " 'n_seeds': 5,\n",
            " 'num_layers': 2,\n",
            " 'num_windows': 100,\n",
            " 'online_signature_calc': False,\n",
            " 'optimizer': 'Adam',\n",
            " 'overlap': False,\n",
            " 'pretrained_model_path': '',\n",
            " 'q_len': 1,\n",
            " 'random_percentage': 0.7,\n",
            " 'resid_pdrop': 0.1,\n",
            " 'save_all_epochs': False,\n",
            " 'scale_att': False,\n",
            " 'sig_level': 2,\n",
            " 'sig_win_len': 50,\n",
            " 'sparse': False,\n",
            " 'std_for_convergence': 0.05,\n",
            " 'sub_len': 1,\n",
            " 'test_size': 0.3,\n",
            " 'univariate': True,\n",
            " 'use_random_drop': False,\n",
            " 'use_signatures': True,\n",
            " 'v_partition': 0.1,\n",
            " 'val_size': 0.5,\n",
            " 'wandb': False,\n",
            " 'warmup_proportion': -1,\n",
            " 'weight_decay': 0,\n",
            " 'zero_shot_downsample': False}\n",
            "\n",
            "Seed: 46\n",
            "\n",
            "######################################\n",
            "Num features without signature:  6 Num features with signatures:  36\n",
            "Sequence length without signature:  896 Sequence length with signatures:  100\n",
            "\n",
            "Compression: 0.6696428571428571\n",
            "\n",
            "Compression L^2d: 0.07473692602040816\n",
            "\n",
            "Number of classes: 2\n",
            "---- Attn\n",
            "Query_Key_CNN: 12972\n",
            "Value_CNN: 6486\n",
            "C_proj_CNN: 6394\n",
            "--- Block\n",
            "attn: 25852\n",
            "mlp: 17158\n",
            "-- Transformer\n",
            "blocks: 86388\n",
            "po_embed: 1000\n",
            "-Decoder Transformer\n",
            "mlp: 94\n",
            "transformer: 87388\n",
            "Epoch 1/110, Loss: 0.6613, Valid Accuracy: 81.18%, Best Valid Accuracy: 81.18%, Test accuracy: 78.57%\n",
            "Epoch 2/110, Loss: 0.5689, Valid Accuracy: 78.82%, Best Valid Accuracy: 81.18%, Test accuracy: 83.33%\n",
            "Epoch 3/110, Loss: 0.3728, Valid Accuracy: 81.18%, Best Valid Accuracy: 81.18%, Test accuracy: 84.52%\n",
            "Epoch 4/110, Loss: 0.6017, Valid Accuracy: 83.53%, Best Valid Accuracy: 83.53%, Test accuracy: 84.52%\n",
            "Epoch 5/110, Loss: 0.4830, Valid Accuracy: 77.65%, Best Valid Accuracy: 83.53%, Test accuracy: 84.52%\n",
            "Epoch 6/110, Loss: 0.7096, Valid Accuracy: 80.00%, Best Valid Accuracy: 83.53%, Test accuracy: 84.52%\n",
            "Epoch 7/110, Loss: 0.8131, Valid Accuracy: 87.06%, Best Valid Accuracy: 87.06%, Test accuracy: 82.14%\n",
            "Epoch 8/110, Loss: 0.4133, Valid Accuracy: 84.71%, Best Valid Accuracy: 87.06%, Test accuracy: 84.52%\n",
            "Epoch 9/110, Loss: 0.4975, Valid Accuracy: 84.71%, Best Valid Accuracy: 87.06%, Test accuracy: 85.71%\n",
            "Epoch 10/110, Loss: 0.3542, Valid Accuracy: 84.71%, Best Valid Accuracy: 87.06%, Test accuracy: 84.52%\n",
            "Epoch 11/110, Loss: 0.3065, Valid Accuracy: 87.06%, Best Valid Accuracy: 87.06%, Test accuracy: 88.10%\n",
            "Epoch 12/110, Loss: 0.1030, Valid Accuracy: 85.88%, Best Valid Accuracy: 87.06%, Test accuracy: 86.90%\n",
            "Epoch 13/110, Loss: 0.2383, Valid Accuracy: 87.06%, Best Valid Accuracy: 87.06%, Test accuracy: 85.71%\n",
            "Epoch 14/110, Loss: 0.3401, Valid Accuracy: 83.53%, Best Valid Accuracy: 87.06%, Test accuracy: 84.52%\n",
            "Epoch 15/110, Loss: 0.1811, Valid Accuracy: 83.53%, Best Valid Accuracy: 87.06%, Test accuracy: 85.71%\n",
            "Epoch 16/110, Loss: 0.2088, Valid Accuracy: 84.71%, Best Valid Accuracy: 87.06%, Test accuracy: 85.71%\n",
            "Epoch 17/110, Loss: 0.1241, Valid Accuracy: 82.35%, Best Valid Accuracy: 87.06%, Test accuracy: 86.90%\n",
            "Epoch 18/110, Loss: 0.1747, Valid Accuracy: 83.53%, Best Valid Accuracy: 87.06%, Test accuracy: 89.29%\n",
            "Epoch 19/110, Loss: 0.3790, Valid Accuracy: 85.88%, Best Valid Accuracy: 87.06%, Test accuracy: 83.33%\n",
            "Epoch 20/110, Loss: 0.1232, Valid Accuracy: 82.35%, Best Valid Accuracy: 87.06%, Test accuracy: 80.95%\n",
            "Epoch 21/110, Loss: 0.1659, Valid Accuracy: 82.35%, Best Valid Accuracy: 87.06%, Test accuracy: 82.14%\n",
            "Epoch 22/110, Loss: 0.3525, Valid Accuracy: 82.35%, Best Valid Accuracy: 87.06%, Test accuracy: 84.52%\n",
            "Epoch 23/110, Loss: 0.1628, Valid Accuracy: 82.35%, Best Valid Accuracy: 87.06%, Test accuracy: 85.71%\n",
            "Epoch 24/110, Loss: 0.1121, Valid Accuracy: 83.53%, Best Valid Accuracy: 87.06%, Test accuracy: 88.10%\n",
            "Epoch 25/110, Loss: 0.0849, Valid Accuracy: 81.18%, Best Valid Accuracy: 87.06%, Test accuracy: 86.90%\n",
            "Epoch 26/110, Loss: 0.1667, Valid Accuracy: 82.35%, Best Valid Accuracy: 87.06%, Test accuracy: 89.29%\n",
            "Epoch 27/110, Loss: 0.6016, Valid Accuracy: 78.82%, Best Valid Accuracy: 87.06%, Test accuracy: 85.71%\n",
            "Epoch 28/110, Loss: 0.4200, Valid Accuracy: 82.35%, Best Valid Accuracy: 87.06%, Test accuracy: 85.71%\n",
            "Epoch 29/110, Loss: 0.0869, Valid Accuracy: 83.53%, Best Valid Accuracy: 87.06%, Test accuracy: 85.71%\n",
            "Epoch 30/110, Loss: 0.1196, Valid Accuracy: 81.18%, Best Valid Accuracy: 87.06%, Test accuracy: 85.71%\n",
            "Epoch 31/110, Loss: 0.3469, Valid Accuracy: 84.71%, Best Valid Accuracy: 87.06%, Test accuracy: 80.95%\n",
            "Epoch 32/110, Loss: 0.0990, Valid Accuracy: 83.53%, Best Valid Accuracy: 87.06%, Test accuracy: 84.52%\n",
            "Epoch 33/110, Loss: 0.3010, Valid Accuracy: 80.00%, Best Valid Accuracy: 87.06%, Test accuracy: 86.90%\n",
            "Epoch 34/110, Loss: 0.2360, Valid Accuracy: 80.00%, Best Valid Accuracy: 87.06%, Test accuracy: 80.95%\n",
            "Epoch 35/110, Loss: 0.1395, Valid Accuracy: 81.18%, Best Valid Accuracy: 87.06%, Test accuracy: 80.95%\n",
            "Epoch 36/110, Loss: 0.2319, Valid Accuracy: 81.18%, Best Valid Accuracy: 87.06%, Test accuracy: 77.38%\n",
            "Epoch 37/110, Loss: 0.1465, Valid Accuracy: 84.71%, Best Valid Accuracy: 87.06%, Test accuracy: 79.76%\n",
            "Epoch 38/110, Loss: 0.4328, Valid Accuracy: 81.18%, Best Valid Accuracy: 87.06%, Test accuracy: 79.76%\n",
            "Epoch 39/110, Loss: 0.2144, Valid Accuracy: 81.18%, Best Valid Accuracy: 87.06%, Test accuracy: 80.95%\n",
            "Epoch 40/110, Loss: 0.0259, Valid Accuracy: 84.71%, Best Valid Accuracy: 87.06%, Test accuracy: 84.52%\n",
            "Epoch 41/110, Loss: 0.0468, Valid Accuracy: 84.71%, Best Valid Accuracy: 87.06%, Test accuracy: 83.33%\n",
            "Epoch 42/110, Loss: 0.2601, Valid Accuracy: 85.88%, Best Valid Accuracy: 87.06%, Test accuracy: 83.33%\n",
            "Epoch 43/110, Loss: 0.3204, Valid Accuracy: 84.71%, Best Valid Accuracy: 87.06%, Test accuracy: 80.95%\n",
            "Epoch 44/110, Loss: 0.2536, Valid Accuracy: 81.18%, Best Valid Accuracy: 87.06%, Test accuracy: 78.57%\n",
            "Epoch 45/110, Loss: 0.2882, Valid Accuracy: 80.00%, Best Valid Accuracy: 87.06%, Test accuracy: 78.57%\n",
            "Epoch 46/110, Loss: 0.0887, Valid Accuracy: 85.88%, Best Valid Accuracy: 87.06%, Test accuracy: 83.33%\n",
            "Epoch 47/110, Loss: 0.1580, Valid Accuracy: 85.88%, Best Valid Accuracy: 87.06%, Test accuracy: 82.14%\n",
            "Epoch 48/110, Loss: 0.1173, Valid Accuracy: 87.06%, Best Valid Accuracy: 87.06%, Test accuracy: 83.33%\n",
            "Epoch 49/110, Loss: 0.1436, Valid Accuracy: 87.06%, Best Valid Accuracy: 87.06%, Test accuracy: 83.33%\n",
            "Epoch 50/110, Loss: 0.0440, Valid Accuracy: 84.71%, Best Valid Accuracy: 87.06%, Test accuracy: 79.76%\n",
            "Epoch 51/110, Loss: 0.2624, Valid Accuracy: 85.88%, Best Valid Accuracy: 87.06%, Test accuracy: 82.14%\n",
            "Epoch 52/110, Loss: 0.0835, Valid Accuracy: 85.88%, Best Valid Accuracy: 87.06%, Test accuracy: 82.14%\n",
            "Epoch 53/110, Loss: 0.2723, Valid Accuracy: 87.06%, Best Valid Accuracy: 87.06%, Test accuracy: 80.95%\n",
            "Epoch 54/110, Loss: 0.1346, Valid Accuracy: 87.06%, Best Valid Accuracy: 87.06%, Test accuracy: 80.95%\n",
            "Epoch 55/110, Loss: 0.0738, Valid Accuracy: 84.71%, Best Valid Accuracy: 87.06%, Test accuracy: 82.14%\n",
            "Epoch 56/110, Loss: 0.2298, Valid Accuracy: 85.88%, Best Valid Accuracy: 87.06%, Test accuracy: 82.14%\n",
            "Epoch 57/110, Loss: 0.0347, Valid Accuracy: 84.71%, Best Valid Accuracy: 87.06%, Test accuracy: 78.57%\n",
            "Epoch 58/110, Loss: 0.2379, Valid Accuracy: 83.53%, Best Valid Accuracy: 87.06%, Test accuracy: 82.14%\n",
            "Epoch 59/110, Loss: 0.0408, Valid Accuracy: 83.53%, Best Valid Accuracy: 87.06%, Test accuracy: 82.14%\n",
            "Epoch 60/110, Loss: 0.2230, Valid Accuracy: 85.88%, Best Valid Accuracy: 87.06%, Test accuracy: 79.76%\n",
            "Epoch 61/110, Loss: 0.0300, Valid Accuracy: 88.24%, Best Valid Accuracy: 88.24%, Test accuracy: 80.95%\n",
            "Epoch 62/110, Loss: 0.0651, Valid Accuracy: 85.88%, Best Valid Accuracy: 88.24%, Test accuracy: 80.95%\n",
            "Epoch 63/110, Loss: 0.0192, Valid Accuracy: 87.06%, Best Valid Accuracy: 88.24%, Test accuracy: 83.33%\n",
            "Epoch 64/110, Loss: 0.1029, Valid Accuracy: 83.53%, Best Valid Accuracy: 88.24%, Test accuracy: 79.76%\n",
            "Epoch 65/110, Loss: 0.2120, Valid Accuracy: 85.88%, Best Valid Accuracy: 88.24%, Test accuracy: 80.95%\n",
            "Epoch 66/110, Loss: 0.1758, Valid Accuracy: 82.35%, Best Valid Accuracy: 88.24%, Test accuracy: 83.33%\n",
            "Epoch 67/110, Loss: 0.0145, Valid Accuracy: 85.88%, Best Valid Accuracy: 88.24%, Test accuracy: 85.71%\n",
            "Epoch 68/110, Loss: 0.0190, Valid Accuracy: 83.53%, Best Valid Accuracy: 88.24%, Test accuracy: 84.52%\n",
            "Epoch 69/110, Loss: 0.0796, Valid Accuracy: 82.35%, Best Valid Accuracy: 88.24%, Test accuracy: 86.90%\n",
            "Epoch 70/110, Loss: 0.0211, Valid Accuracy: 82.35%, Best Valid Accuracy: 88.24%, Test accuracy: 85.71%\n",
            "Epoch 71/110, Loss: 0.0963, Valid Accuracy: 85.88%, Best Valid Accuracy: 88.24%, Test accuracy: 84.52%\n",
            "Epoch 72/110, Loss: 0.1053, Valid Accuracy: 88.24%, Best Valid Accuracy: 88.24%, Test accuracy: 88.10%\n",
            "Epoch 73/110, Loss: 0.2218, Valid Accuracy: 85.88%, Best Valid Accuracy: 88.24%, Test accuracy: 86.90%\n",
            "Epoch 74/110, Loss: 0.3617, Valid Accuracy: 84.71%, Best Valid Accuracy: 88.24%, Test accuracy: 77.38%\n",
            "Epoch 75/110, Loss: 0.0917, Valid Accuracy: 85.88%, Best Valid Accuracy: 88.24%, Test accuracy: 84.52%\n",
            "Epoch 76/110, Loss: 0.0901, Valid Accuracy: 85.88%, Best Valid Accuracy: 88.24%, Test accuracy: 85.71%\n",
            "Epoch 77/110, Loss: 0.0347, Valid Accuracy: 85.88%, Best Valid Accuracy: 88.24%, Test accuracy: 84.52%\n",
            "Epoch 78/110, Loss: 0.0262, Valid Accuracy: 84.71%, Best Valid Accuracy: 88.24%, Test accuracy: 84.52%\n",
            "Epoch 79/110, Loss: 0.0273, Valid Accuracy: 87.06%, Best Valid Accuracy: 88.24%, Test accuracy: 82.14%\n",
            "Epoch 80/110, Loss: 0.0123, Valid Accuracy: 84.71%, Best Valid Accuracy: 88.24%, Test accuracy: 84.52%\n",
            "Epoch 81/110, Loss: 0.2357, Valid Accuracy: 83.53%, Best Valid Accuracy: 88.24%, Test accuracy: 84.52%\n",
            "Epoch 82/110, Loss: 0.2241, Valid Accuracy: 82.35%, Best Valid Accuracy: 88.24%, Test accuracy: 84.52%\n",
            "Epoch 83/110, Loss: 0.0310, Valid Accuracy: 83.53%, Best Valid Accuracy: 88.24%, Test accuracy: 84.52%\n",
            "Epoch 84/110, Loss: 0.0926, Valid Accuracy: 83.53%, Best Valid Accuracy: 88.24%, Test accuracy: 84.52%\n",
            "Epoch 85/110, Loss: 0.0223, Valid Accuracy: 81.18%, Best Valid Accuracy: 88.24%, Test accuracy: 84.52%\n",
            "Epoch 86/110, Loss: 0.0171, Valid Accuracy: 84.71%, Best Valid Accuracy: 88.24%, Test accuracy: 84.52%\n",
            "Epoch 87/110, Loss: 0.0042, Valid Accuracy: 82.35%, Best Valid Accuracy: 88.24%, Test accuracy: 85.71%\n",
            "Epoch 88/110, Loss: 0.0062, Valid Accuracy: 80.00%, Best Valid Accuracy: 88.24%, Test accuracy: 84.52%\n",
            "Epoch 89/110, Loss: 0.0937, Valid Accuracy: 78.82%, Best Valid Accuracy: 88.24%, Test accuracy: 83.33%\n",
            "Epoch 90/110, Loss: 0.0068, Valid Accuracy: 76.47%, Best Valid Accuracy: 88.24%, Test accuracy: 79.76%\n",
            "Epoch 91/110, Loss: 0.0227, Valid Accuracy: 82.35%, Best Valid Accuracy: 88.24%, Test accuracy: 80.95%\n",
            "Epoch 92/110, Loss: 0.0065, Valid Accuracy: 80.00%, Best Valid Accuracy: 88.24%, Test accuracy: 82.14%\n",
            "Epoch 93/110, Loss: 0.0012, Valid Accuracy: 80.00%, Best Valid Accuracy: 88.24%, Test accuracy: 82.14%\n",
            "Epoch 94/110, Loss: 0.0087, Valid Accuracy: 81.18%, Best Valid Accuracy: 88.24%, Test accuracy: 83.33%\n",
            "Epoch 95/110, Loss: 0.0134, Valid Accuracy: 83.53%, Best Valid Accuracy: 88.24%, Test accuracy: 84.52%\n",
            "Epoch 96/110, Loss: 0.0013, Valid Accuracy: 84.71%, Best Valid Accuracy: 88.24%, Test accuracy: 83.33%\n",
            "Epoch 97/110, Loss: 0.0056, Valid Accuracy: 82.35%, Best Valid Accuracy: 88.24%, Test accuracy: 83.33%\n",
            "Epoch 98/110, Loss: 0.0007, Valid Accuracy: 81.18%, Best Valid Accuracy: 88.24%, Test accuracy: 83.33%\n",
            "Epoch 99/110, Loss: 0.0019, Valid Accuracy: 83.53%, Best Valid Accuracy: 88.24%, Test accuracy: 83.33%\n",
            "Epoch 100/110, Loss: 0.0218, Valid Accuracy: 82.35%, Best Valid Accuracy: 88.24%, Test accuracy: 85.71%\n",
            "Epoch 101/110, Loss: 0.1458, Valid Accuracy: 78.82%, Best Valid Accuracy: 88.24%, Test accuracy: 80.95%\n",
            "Epoch 102/110, Loss: 0.0023, Valid Accuracy: 74.12%, Best Valid Accuracy: 88.24%, Test accuracy: 77.38%\n",
            "Epoch 103/110, Loss: 0.0015, Valid Accuracy: 78.82%, Best Valid Accuracy: 88.24%, Test accuracy: 79.76%\n",
            "Epoch 104/110, Loss: 0.1610, Valid Accuracy: 78.82%, Best Valid Accuracy: 88.24%, Test accuracy: 83.33%\n",
            "Epoch 105/110, Loss: 0.0182, Valid Accuracy: 82.35%, Best Valid Accuracy: 88.24%, Test accuracy: 88.10%\n",
            "Epoch 106/110, Loss: 0.0015, Valid Accuracy: 81.18%, Best Valid Accuracy: 88.24%, Test accuracy: 82.14%\n",
            "Epoch 107/110, Loss: 0.0698, Valid Accuracy: 77.65%, Best Valid Accuracy: 88.24%, Test accuracy: 84.52%\n",
            "Epoch 108/110, Loss: 0.1243, Valid Accuracy: 81.18%, Best Valid Accuracy: 88.24%, Test accuracy: 82.14%\n",
            "Epoch 109/110, Loss: 0.2540, Valid Accuracy: 83.53%, Best Valid Accuracy: 88.24%, Test accuracy: 83.33%\n",
            "Epoch 110/110, Loss: 0.0501, Valid Accuracy: 77.65%, Best Valid Accuracy: 88.24%, Test accuracy: 83.33%\n",
            "Training time: 25.48 seconds\n",
            "Total time: 26.60 seconds\n",
            "0.8333333333333334\n",
            "Average accuracy: 0.8238095238095238, Std: 0.030491067797299282\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# os.chdir(\"UEA\")\n",
        "# !ls\n",
        "\n",
        "!python UEA/main.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "ULZgRvmILSfQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "tbs8G_gELSpp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "eIKm4D7xLSxk"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO6isKiaLPwk+XSmeDW2s5L",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}